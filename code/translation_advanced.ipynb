{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine translation (advanced)\n",
    "\n",
    "| Authors | Last update |\n",
    "|:------ |:----------- |\n",
    "| Hauke Licht (https://github.com/haukelicht) | 2023-12-05 |\n",
    "\n",
    "<br>\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/fabiennelind/Going-Cross-Lingual_Course/blob/main/code/translation_advanced.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run notebooks on **Colab**, you can **enable GPU** computing by\n",
    "\n",
    "1. clicking on \"Runtime\" in the menu,\n",
    "2. selecting \"Change runtime type\", and\n",
    "3. choose \"GPU\" in the \"Hardware accelerator\" section of the pop-up\n",
    "\n",
    "This speeds up computing of deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on colab: False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "except:\n",
    "    COLAB=False\n",
    "print('on colab:', COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# need to install libraries if on Colab\n",
    "%%capture\n",
    "if COLAB:\n",
    "    !pip install iso639==0.1.4 torch==2.1.0 easynmt==2.0.0 deepl==1.16.1 google-cloud-translate==3.12.1 sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import iso639\n",
    "\n",
    "import torch\n",
    "\n",
    "import easynmt\n",
    "import deepl\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import translate_v2 as gt\n",
    "\n",
    "base_path = os.path.join('..')\n",
    "data_path = os.path.join(base_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [PimPo](https://manifesto-project.wzb.eu/information/documents/pimpo) dataset that records party manifesto quasi-sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    fp = \"https://raw.githubusercontent.com/fabiennelind/Going-Cross-Lingual_Course/main/data/lehmann%2Bzobel_2018_labeled_manifestos.tsv\"\n",
    "else:\n",
    "    fp = os.path.join(data_path, 'lehmann+zobel_2018_labeled_manifestos.tsv')\n",
    "df = pd.read_csv(fp, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of manifestos\n",
    "len(df.manifesto_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 234111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lang\n",
       "deu    66255\n",
       "spa    40074\n",
       "eng    36621\n",
       "nor    33544\n",
       "nld    30931\n",
       "swe     8210\n",
       "fin     7888\n",
       "dan     6453\n",
       "fra     4135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# big dataset with broad language coverage\n",
    "print('N =', len(df))\n",
    "df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the dataset is quite big.\n",
    "Let's see what it'd cost us to translate it with a commercial service (Google or DeepL):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# characters 26.510575\n",
      "approx. costs (in EUR or $) = 530.2115\n"
     ]
    }
   ],
   "source": [
    "# count number of characters\n",
    "print('# characters', df.text.apply(len).sum() / 1_000_000) # in millions\n",
    "# translating 1 mio characters costs about 20 EUR with DeepL and 20 U.S. Dollars with Google\n",
    "print('approx. costs (in EUR or $) =', (df.text.apply(len).sum() / 1_000_000) * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for practical purposes, we subset the dataset to sentences about the issues of immigration or integration (they have stance codings).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue\n",
      "other          225166\n",
      "integration      5052\n",
      "immigration      3893\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.issue.value_counts())\n",
    "df = df[df.issue.isin(['integration', 'immigration'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# characters =~ 1.040 mio\n",
      "approximate costs =~ 20.80 EUR\n"
     ]
    }
   ],
   "source": [
    "print(f'# characters =~ {df.text.apply(len).sum() / 1_000_000:.03f} mio')\n",
    "print(f'approximate costs =~ {(df.text.apply(len).sum() / 1_000_000)*20:.02f} EUR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better.\n",
    "We have prepare the data in a separate data file, which we load instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    fp = fp = \"https://raw.githubusercontent.com/fabiennelind/Going-Cross-Lingual_Course/main/data/lehmann%2Bzobel_2018_pimpo_positions.tsv\"\n",
    "else:\n",
    "    fp = os.path.join(data_path, 'lehmann+zobel_2018_pimpo_positions.tsv')\n",
    "df = pd.read_csv(fp, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "position\n",
       "supportive    5841\n",
       "sceptical     2136\n",
       "neutral        968\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.position.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an advanced translation function: illustration with easyNMT's M2M model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easynmt\n",
    "model = easynmt.EasyNMT('m2m_100_418M', device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a helper function that allows to split a list into smaller chunks.\n",
    "We will use this to safely translate a large list of sentences in smaller portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk nr. 0 has 3 element(s): ['a', 'b', 'c']\n",
      "chunk nr. 1 has 3 element(s): ['d', 'e', 'f']\n",
      "chunk nr. 2 has 3 element(s): ['g', 'h', 'i']\n",
      "chunk nr. 3 has 1 element(s): ['j']\n"
     ]
    }
   ],
   "source": [
    "# chunk list of sentences into smaller chunks\n",
    "def chunk(lst, size):\n",
    "    for i in range(0, len(lst), size):\n",
    "        yield lst[i:i + size]\n",
    "\n",
    "# example: split list with first 10 letters in alphabet into chunks of 3\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "for i, c in enumerate(chunk(alphabet, 3)):\n",
    "    print(f'chunk nr. {i} has {len(c)} element(s): {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a function for freeing up GPU memory if we run into overflow issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def clean_memory(device):\n",
    "    if 'cuda' in str(device):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    elif 'mps' in str(device):\n",
    "        torch.mps.empty_cache()\n",
    "        torch.mps.release_buffers()\n",
    "    else:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define the first translation function.\n",
    "It takes a list of texts and applies a translation function, which is passed to the `translation_fun` argument\n",
    "(This should be a function that takes a list of texts and returns a list of translations.)\n",
    "\n",
    "The cool thing about `translate_batch_safely` is that if it runs into GPU memory issues, it tries to translate the texts one by one (instead of all in one batch).\n",
    "This avoids breaking the proecss due to single overflow errors.\n",
    "Hence, the \"safely\" in the function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Callable, Union\n",
    "\n",
    "def translate_batch_safely(texts: list, translation_fun: Callable, device: Union[str, torch.device], **kwargs) -> list:\n",
    "    \"\"\"\n",
    "    Translates a batch of texts using the model, handling potential errors.\n",
    "\n",
    "    Parameters:\n",
    "        texts (list): A list of texts to be translated.\n",
    "        translation_fun (Callable): The translation function to be used.\n",
    "        **kwargs: Additional keyword arguments to be passed to `translation_fun`.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of translated texts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to translate the batch of texts using the model\n",
    "        res = translation_fun(texts, **kwargs)\n",
    "    except Exception as e:\n",
    "        # If the exception is _not_ related to running out of memory, ...\n",
    "        if 'out of memory' not in str(e):\n",
    "            # ... raise the exception\n",
    "            raise e\n",
    "        # but if the error was due running out of memory, ...\n",
    "        else:\n",
    "            # get the key-value arguments\n",
    "            args = dict(**kwargs)\n",
    "            # drop the batch size (will be set to 1 below)\n",
    "            if 'batch_size' in args:\n",
    "              del args['batch_size']\n",
    "\n",
    "            clean_memory(device)\n",
    "            res = [None] * len(texts)\n",
    "            # ... try translating each text individually\n",
    "            for i, text in enumerate(texts):\n",
    "                try:\n",
    "                    res[i] = translation_fun(text, batch_size=1, **args)\n",
    "                except Exception as e:\n",
    "                    # If unable to translate a text, print a warning message\n",
    "                    print(f'WARNING: couldn\\'t translate text \"{text[:min(30, len(text))]}\". Reason: {str(e)}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function that translates a list of texts by internally splitting it into smaller chunks and calling translate batch safely.\n",
    "Note that the `translation_fun` argument required by `tranlate_batch_safely` is just passed onwards as a keyword argument (captured by the `**kwargs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def translate_in_batches(texts: list, batch_size, verbose=False, pbar_desc=None, **kwargs) -> list:\n",
    "    \"\"\"\n",
    "    Translates a list of texts in batches using the `translate_batch_safely` function.\n",
    "\n",
    "    Parameters:\n",
    "        texts (list): A list of texts to be translated.\n",
    "        batch_size (int): The size of each translation batch.\n",
    "        verbose (bool): Whether to print messages and a progress bar\n",
    "        pbard_desc (str): The description of the progress bar\n",
    "        **kwargs: Additional keyword arguments to be passed to the `translate_batch_safely` function.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of translated texts.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the translations\n",
    "    translations = []\n",
    "    n_batches = len(texts)//batch_size\n",
    "    if verbose:\n",
    "        pbar = tqdm(total=n_batches, desc=pbar_desc)\n",
    "    # Iterate over the batches of texts\n",
    "    for batch in chunk(texts, batch_size):\n",
    "        # Translate the batch of texts\n",
    "        translations += translate_batch_safely(batch, **kwargs)\n",
    "        if verbose: \n",
    "            pbar.update(1)\n",
    "    if verbose: \n",
    "        pbar.close()\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with one source language\n",
    "\n",
    "Let's take a sample of sentences from the German-language subset of our dataset and translate them to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. sentences = 16\n"
     ]
    }
   ],
   "source": [
    "b = 8 # <== batch size\n",
    "expls = df.text[df.lang == 'deu'].tolist()\n",
    "expls = expls[:b*2]\n",
    "print('No. sentences =', len(expls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Instead of democratically integrating the interests of all stakeholders, it sets on division: workers against unemployed, west against east, healthy against sick, boys against old, men against women, Germans against foreigners, singles against families.',\n",
       " 'Where the law of the stronger applies, hatred and violence are not far away.',\n",
       " 'Five years after the fires in Solingen and Lübeck, extreme-right violence continues to be bitter everyday.',\n",
       " 'Five years after the abolition of the asylum law, people in Germany must seek asylum before the police in churches',\n",
       " 'Millions of citizens are still denied citizenship rights',\n",
       " 'A disgraceful foreign domestic policy pushes especially young migrants to the edge of society',\n",
       " 'Green wants to oppose a policy in which young people can participate actively and which takes their experiences and conditions of life seriously.',\n",
       " 'Chancellor words such as “Free-Time Park” and campaigns against the “abuse” of the social security system or against foreign workers make the concerned guilty',\n",
       " 'Full employment means the opening of existential participation in employment for all seekers of employment, women and men.',\n",
       " 'Discrimination of migrants and persons with disabilities, as well as employment prohibitions for asylum seekers',\n",
       " 'Groups with special problems on the labour market – long-term unemployed, people with disabilities, low-qualified, school-free youth and foreigners – need to be integrated and supported.',\n",
       " 'Foreigners living in Germany should not be discriminated in social policy.',\n",
       " 'Refugees are allowed to receive no less subsidiary than Germans in need.',\n",
       " 'Maintenance aid, unemployment aid and benefits pursuant to the Asylum Appeal Act shall be resolved by a need-oriented basic insurance.',\n",
       " 'We want to cover the socio-cultural minimum needs for all those who do not have sufficient income or wealth and who live in Germany, regardless of nationality and residence status.',\n",
       " 'Prostitution must be recognized as a professional activity.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_in_batches(\n",
    "    texts=expls, \n",
    "    translation_fun=model.translate, # <== use esayNMT model's translate method\n",
    "    device=model.device, \n",
    "    batch_size=b, # <== batch size\n",
    "    # arguments forwarded to `translation_fun``\n",
    "    source_lang='de', \n",
    "    target_lang='en', \n",
    "    beam_size=5,\n",
    "    perform_sentence_splitting=False, \n",
    "    show_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* takes some time if you run it without a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with multiple source languages\n",
    "\n",
    "Next, take samples of sentences from the German-, Finish- and Spanish-language subsets of our dataset and translate them to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa</td>\n",
       "      <td>Los inmigrantes han rejuvenecido nuestra pobla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa</td>\n",
       "      <td>así como proyectar la acción del Gobierno en c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deu</td>\n",
       "      <td>§ Integration fördern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa</td>\n",
       "      <td>Ello requiere una vigilancia mayor y más solid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kun keskustelu kiehuu, on vaarana, että huudam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deu</td>\n",
       "      <td>Junge Deutsche, die auch noch den Pass eines a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deu</td>\n",
       "      <td>Die von den Kantonen und Gemeinden eingerichte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa</td>\n",
       "      <td>Apoyaremos de manera decidida las iniciativas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fin</td>\n",
       "      <td>On tärkeää ymmärtää maahanmuuton syitä ja muut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fin</td>\n",
       "      <td>Maahanmuuttaja- ja romaniperheiden lapsia tule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wir wollen zudem die Ausbildungs- und Arbeitsv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kristillisdemokraatit haastavat suomalaiset ka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang                                               text\n",
       "0   spa  Los inmigrantes han rejuvenecido nuestra pobla...\n",
       "1   spa  así como proyectar la acción del Gobierno en c...\n",
       "2   deu                              § Integration fördern\n",
       "3   spa  Ello requiere una vigilancia mayor y más solid...\n",
       "4   fin  Kun keskustelu kiehuu, on vaarana, että huudam...\n",
       "5   deu  Junge Deutsche, die auch noch den Pass eines a...\n",
       "6   deu  Die von den Kantonen und Gemeinden eingerichte...\n",
       "7   spa  Apoyaremos de manera decidida las iniciativas ...\n",
       "8   fin  On tärkeää ymmärtää maahanmuuton syitä ja muut...\n",
       "9   fin  Maahanmuuttaja- ja romaniperheiden lapsia tule...\n",
       "10  deu  Wir wollen zudem die Ausbildungs- und Arbeitsv...\n",
       "11  fin  Kristillisdemokraatit haastavat suomalaiset ka..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 4 # <== batch size\n",
    "# subset data to selected languages (for illustration) and columns\n",
    "expls = df.loc[df.lang.isin(['deu', 'fin', 'spa']), ['lang', 'text']]\n",
    "# sample 4 sentences per language subset\n",
    "expls = expls.groupby('lang').sample(b, random_state=42)\n",
    "# reshguffle rows and reset index\n",
    "expls = expls.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "expls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translating 4 texts from deu (de)\n",
      "translating 4 texts from fin (fi)\n",
      "translating 4 texts from spa (es)\n"
     ]
    }
   ],
   "source": [
    "# initialize new column for storing translations\n",
    "expls['text_mt_m2m'] = [None]*len(expls)\n",
    "\n",
    "# iterate over languages subsets\n",
    "for l, d in expls.groupby('lang'):\n",
    "    # get the ISO 639-1 language code for the language\n",
    "    lang_code = iso639.to_iso639_1(l)\n",
    "    # note: usually, we want to check beforehand whether the language is supported by the model\n",
    "\n",
    "    print(f'translating {len(d)} texts from {l} ({lang_code})')\n",
    "    # translate texts in batches and assign translations directly into relevant rows of target column (using input data frame's index values)\n",
    "    expls.loc[d.index, 'text_mt_m2m'] = translate_in_batches(\n",
    "        texts=d.text.tolist(), \n",
    "        translation_fun=model.translate,\n",
    "        device=model.device,\n",
    "        batch_size=b, \n",
    "        # arguments forwarded to `translation_fun`\n",
    "        source_lang=lang_code, # <== use current iteration's language\n",
    "        target_lang='en', \n",
    "        beam_size=5,\n",
    "        perform_sentence_splitting=False,\n",
    "        show_progress_bar=False, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>text_mt_m2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa</td>\n",
       "      <td>Los inmigrantes han rejuvenecido nuestra pobla...</td>\n",
       "      <td>Immigrants have rejuvenated our population and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa</td>\n",
       "      <td>así como proyectar la acción del Gobierno en c...</td>\n",
       "      <td>and project the Government’s action in coopera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deu</td>\n",
       "      <td>§ Integration fördern</td>\n",
       "      <td>Promote integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa</td>\n",
       "      <td>Ello requiere una vigilancia mayor y más solid...</td>\n",
       "      <td>This requires greater surveillance and more so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kun keskustelu kiehuu, on vaarana, että huudam...</td>\n",
       "      <td>When the discussion is boiling, there is a dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deu</td>\n",
       "      <td>Junge Deutsche, die auch noch den Pass eines a...</td>\n",
       "      <td>Young Germans who still have the passport of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deu</td>\n",
       "      <td>Die von den Kantonen und Gemeinden eingerichte...</td>\n",
       "      <td>The existing offers of courses and employment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa</td>\n",
       "      <td>Apoyaremos de manera decidida las iniciativas ...</td>\n",
       "      <td>We will strongly support co-development initia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fin</td>\n",
       "      <td>On tärkeää ymmärtää maahanmuuton syitä ja muut...</td>\n",
       "      <td>It is important to understand the causes of mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fin</td>\n",
       "      <td>Maahanmuuttaja- ja romaniperheiden lapsia tule...</td>\n",
       "      <td>Children from immigrants and Romans should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wir wollen zudem die Ausbildungs- und Arbeitsv...</td>\n",
       "      <td>We also want to eliminate the education and em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kristillisdemokraatit haastavat suomalaiset ka...</td>\n",
       "      <td>Christian Democrats challenge the Finnish to g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang                                               text  \\\n",
       "0   spa  Los inmigrantes han rejuvenecido nuestra pobla...   \n",
       "1   spa  así como proyectar la acción del Gobierno en c...   \n",
       "2   deu                              § Integration fördern   \n",
       "3   spa  Ello requiere una vigilancia mayor y más solid...   \n",
       "4   fin  Kun keskustelu kiehuu, on vaarana, että huudam...   \n",
       "5   deu  Junge Deutsche, die auch noch den Pass eines a...   \n",
       "6   deu  Die von den Kantonen und Gemeinden eingerichte...   \n",
       "7   spa  Apoyaremos de manera decidida las iniciativas ...   \n",
       "8   fin  On tärkeää ymmärtää maahanmuuton syitä ja muut...   \n",
       "9   fin  Maahanmuuttaja- ja romaniperheiden lapsia tule...   \n",
       "10  deu  Wir wollen zudem die Ausbildungs- und Arbeitsv...   \n",
       "11  fin  Kristillisdemokraatit haastavat suomalaiset ka...   \n",
       "\n",
       "                                          text_mt_m2m  \n",
       "0   Immigrants have rejuvenated our population and...  \n",
       "1   and project the Government’s action in coopera...  \n",
       "2                                 Promote integration  \n",
       "3   This requires greater surveillance and more so...  \n",
       "4   When the discussion is boiling, there is a dan...  \n",
       "5   Young Germans who still have the passport of a...  \n",
       "6   The existing offers of courses and employment ...  \n",
       "7   We will strongly support co-development initia...  \n",
       "8   It is important to understand the causes of mi...  \n",
       "9   Children from immigrants and Romans should be ...  \n",
       "10  We also want to eliminate the education and em...  \n",
       "11  Christian Democrats challenge the Finnish to g...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final data frame has the translations\n",
    "expls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap the entire logic into a custom function\n",
    "\n",
    "In many use cases, we want to translate a whole dataset in the form of a data frame.\n",
    "So let's wrap the logic above into a custom function that takes a data frame as input and returns the data frame with the sentence translations added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable, Union, List\n",
    "\n",
    "# helpers\n",
    "def is_string_series(s: pd.Series):\n",
    "    \"\"\"\n",
    "    Test if pandas series is a string series/series of strings\n",
    "    \n",
    "    source: https://stackoverflow.com/a/67001213\n",
    "    \"\"\"\n",
    "    if isinstance(s.dtype, pd.StringDtype):\n",
    "        # The series was explicitly created as a string series (Pandas>=1.0.0)\n",
    "        return True\n",
    "    elif s.dtype == 'object':\n",
    "        # Object series, check each value\n",
    "        return all(isinstance(v, str) or (v is None) or (np.isnan(v)) for v in s)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_nonempty_string(s: pd.Series):\n",
    "    return np.array([isinstance(v, str) and len(v) > 0 for v in s], dtype=bool)\n",
    "\n",
    "# main function\n",
    "def translate_df(\n",
    "        df: pd.DataFrame, \n",
    "        translation_function: Callable,\n",
    "        supported_languages: List[str],\n",
    "        text_col: str = 'text', \n",
    "        lang_col: str = 'lang',\n",
    "        target_language: str = 'en',\n",
    "        target_col: str = 'translation',\n",
    "        device: Union[str, torch.device] = 'cpu',\n",
    "        batch_size: int = 16,\n",
    "        verbose: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Translates the texts in a data frame from the source languages specified in a column to a target language and add the translations to the data frame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the texts to be translated.\n",
    "        translation_function (Callable): The translation function to be used.\n",
    "        supported_languages (List[str]): A list language codes supported by the translation model.\n",
    "        text_col (str): The name of the column in the DataFrame that contains the texts to be translated. Default is 'text'.\n",
    "        lang_col (str): The name of the column in the DataFrame that contains the language codes. Default is 'lang'.\n",
    "        target_language (str): The target language to translate the texts to. Can be either an ISO 639-1 or ISO 639-2 language code. Default is 'en'.\n",
    "        target_col (str): The name of the column in the DataFrame to store the translations. Default is 'translation'.\n",
    "        supported_languages (List[str]): A list of ISO 639-1 or ISO 639-2 language codes supported by the translation model. Default is None.\n",
    "        device (Union[str, torch.device]): The device to use for translation. Default is 'cpu' but should be compatible with device used by translation model.\n",
    "        batch_size (int): The size of each translation batch. Default is 16.\n",
    "        **kwargs: Additional keyword arguments to be passed to the `translate_in_batches` function which, in turn, passes them to the translation function.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the translated texts in column `target_col` in the target language `target_lang`.\n",
    "    \"\"\"\n",
    "    # validate the inputs\n",
    "    assert text_col in df.columns, f'Column \"{text_col}\" not found in data frame.'\n",
    "    assert is_string_series(df[text_col]), f'Column \"{text_col}\" is not a series of string values.'\n",
    "    assert lang_col in df.columns, f'Column \"{lang_col}\" not found in data frame.'\n",
    "    assert is_string_series(df[lang_col]), f'Column \"{lang_col}\" is not a series of string values.'\n",
    "    assert target_language is not None, 'Target language must be specified.'\n",
    "    assert target_col not in df.columns, f'Column \"{target_col}\" already exists in data frame.'\n",
    "    assert translation_function is not None, 'Translation function must be specified.'\n",
    "    assert batch_size > 0, 'Batch size must be greater than 0.'\n",
    "    assert supported_languages is not None, 'Supported languages must be specified.'\n",
    "    assert isinstance(supported_languages, list), 'Supported languages must be a list.'\n",
    "    assert len(supported_languages) > 0, 'Supported languages must not be empty.'\n",
    "    assert all([isinstance(l, str) for l in supported_languages]), 'Supported languages must be a list of strings.'\n",
    "    \n",
    "    # check whether the model supports the target language\n",
    "    langs = df['lang'].unique().tolist()\n",
    "    # try to get the ISO 639-1 or ISO 639-2 language code for each language in the data frame\n",
    "    langs_map = {\n",
    "        l: l if iso639.is_valid639_1(l) else iso639.to_iso639_1(l) if iso639.is_valid639_2(l) else None \n",
    "        for l in langs\n",
    "    }\n",
    "    # check whether there are unsupported languages\n",
    "    not_supported = [\n",
    "        l \n",
    "        for l, c in langs_map.items() \n",
    "        if l not in supported_languages and c not in supported_languages and l != target_language and c != target_language\n",
    "    ]\n",
    "    # print warning message if there are unsupported languages\n",
    "    if len(not_supported) > 0:\n",
    "        print(\n",
    "            f'WARNING: values {not_supported} in column \"{lang_col}\" are not supported by NMT model.',\n",
    "            'Texts with these values will not be translated.'\n",
    "        )\n",
    "    # now update language mapping with \"correct\" language codes (use ISO code if available, otherwise use original indicator from the data frame)\n",
    "    langs_map = {\n",
    "        l: c if c in supported_languages else l if l in supported_languages else None \n",
    "        for l, c in langs_map.items()\n",
    "    }\n",
    "\n",
    "    # create new column for translation\n",
    "    df[target_col] = [None]*len(df)\n",
    "\n",
    "    # iterate over languages\n",
    "    for l, d in df.groupby(lang_col):\n",
    "        lang_code = langs_map[l]\n",
    "        # just copy texts if source language is the target language\n",
    "        if lang_code == target_language or l == target_language:\n",
    "            df.loc[d.index, target_col] = d[text_col].tolist()\n",
    "            continue\n",
    "        # skip unsupported languages\n",
    "        if l in not_supported or lang_code is None:\n",
    "            continue\n",
    "        # test for each text value if non-empty string\n",
    "        flag = is_nonempty_string(d[text_col])\n",
    "        if any(~flag):\n",
    "            print(f'WARNING: {sum(~flag)} empty or non-string text(s) in \"{l}\"')\n",
    "        df.loc[d.index[flag], target_col] = translate_in_batches(\n",
    "            texts=d[text_col][flag].tolist(), # <== only translate non-empty texts\n",
    "            translation_fun=translation_function,\n",
    "            device=device,\n",
    "            batch_size=batch_size, \n",
    "            source_lang=lang_code, \n",
    "            target_lang=target_language,\n",
    "            verbose=verbose, \n",
    "            pbar_desc=f'translating {len(d)} text(s) from \"{l}\"',\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a62bc6f1494422b11c080fb4f691bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"deu\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f288dd23f2d47d29196c585c9891c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"fin\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a796d1aa7298495185e47b6f8a771ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"spa\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>text_mt_m2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa</td>\n",
       "      <td>Los inmigrantes han rejuvenecido nuestra pobla...</td>\n",
       "      <td>Immigrants have rejuvenated our population and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa</td>\n",
       "      <td>así como proyectar la acción del Gobierno en c...</td>\n",
       "      <td>and project the Government’s action in coopera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deu</td>\n",
       "      <td>§ Integration fördern</td>\n",
       "      <td>Promote integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa</td>\n",
       "      <td>Ello requiere una vigilancia mayor y más solid...</td>\n",
       "      <td>This requires greater surveillance and more so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kun keskustelu kiehuu, on vaarana, että huudam...</td>\n",
       "      <td>When the discussion is boiling, there is a dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deu</td>\n",
       "      <td>Junge Deutsche, die auch noch den Pass eines a...</td>\n",
       "      <td>Young Germans who still have the passport of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deu</td>\n",
       "      <td>Die von den Kantonen und Gemeinden eingerichte...</td>\n",
       "      <td>The existing offers of courses and employment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa</td>\n",
       "      <td>Apoyaremos de manera decidida las iniciativas ...</td>\n",
       "      <td>We will strongly support co-development initia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fin</td>\n",
       "      <td>On tärkeää ymmärtää maahanmuuton syitä ja muut...</td>\n",
       "      <td>It is important to understand the causes of mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fin</td>\n",
       "      <td>Maahanmuuttaja- ja romaniperheiden lapsia tule...</td>\n",
       "      <td>Children from immigrants and Romans should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wir wollen zudem die Ausbildungs- und Arbeitsv...</td>\n",
       "      <td>We also want to eliminate the education and em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kristillisdemokraatit haastavat suomalaiset ka...</td>\n",
       "      <td>Christian Democrats challenge the Finnish to g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang                                               text  \\\n",
       "0   spa  Los inmigrantes han rejuvenecido nuestra pobla...   \n",
       "1   spa  así como proyectar la acción del Gobierno en c...   \n",
       "2   deu                              § Integration fördern   \n",
       "3   spa  Ello requiere una vigilancia mayor y más solid...   \n",
       "4   fin  Kun keskustelu kiehuu, on vaarana, että huudam...   \n",
       "5   deu  Junge Deutsche, die auch noch den Pass eines a...   \n",
       "6   deu  Die von den Kantonen und Gemeinden eingerichte...   \n",
       "7   spa  Apoyaremos de manera decidida las iniciativas ...   \n",
       "8   fin  On tärkeää ymmärtää maahanmuuton syitä ja muut...   \n",
       "9   fin  Maahanmuuttaja- ja romaniperheiden lapsia tule...   \n",
       "10  deu  Wir wollen zudem die Ausbildungs- und Arbeitsv...   \n",
       "11  fin  Kristillisdemokraatit haastavat suomalaiset ka...   \n",
       "\n",
       "                                          text_mt_m2m  \n",
       "0   Immigrants have rejuvenated our population and...  \n",
       "1   and project the Government’s action in coopera...  \n",
       "2                                 Promote integration  \n",
       "3   This requires greater surveillance and more so...  \n",
       "4   When the discussion is boiling, there is a dan...  \n",
       "5   Young Germans who still have the passport of a...  \n",
       "6   The existing offers of courses and employment ...  \n",
       "7   We will strongly support co-development initia...  \n",
       "8   It is important to understand the causes of mi...  \n",
       "9   Children from immigrants and Romans should be ...  \n",
       "10  We also want to eliminate the education and em...  \n",
       "11  Christian Democrats challenge the Finnish to g...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the example sentences from above again (but delete previously translations)\n",
    "if 'text_mt_m2m' in expls.columns:\n",
    "    del expls['text_mt_m2m']\n",
    "\n",
    "# translate\n",
    "expls = translate_df(\n",
    "    df=expls, \n",
    "    # data frame arguments\n",
    "    text_col='text',\n",
    "    target_language='en', \n",
    "    target_col='text_mt_m2m',\n",
    "    # translation model arguments\n",
    "    translation_function=model.translate,\n",
    "    supported_languages=model.get_languages(),\n",
    "    batch_size=4, # <== use small batch size for illustration \n",
    "    device=model.device,\n",
    "    # arguments forwarded to model.translate()\n",
    "    beam_size=5,\n",
    "    perform_sentence_splitting=False,\n",
    "    show_progress_bar=False, \n",
    "    # print progress bar\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "expls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage the flexibilits of `translate_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can leverage the flexibility of `translate_df` to create three specialized translation functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### translate data frame with easyNMT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "def translate_df_with_easynmt(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Translates a DataFrame using the EasyNMT model.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to be translated.\n",
    "        args: Additional arguments for the translation process.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The translated DataFrame.\n",
    "    \"\"\"\n",
    "    args = SimpleNamespace(**kwargs)\n",
    "\n",
    "    try:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "        model = easynmt.EasyNMT(args.model_name, device=device)\n",
    "        print(f'Using device \"{model.device}\"')\n",
    "    except Exception as e:\n",
    "        print(f'WARNING: could not load model \"{args.model_name}\"')\n",
    "        raise e\n",
    "    \n",
    "    tgt_lang = [l.lower() for l in model.get_languages() if args.target_language.lower() == l.lower() or args.target_language.lower() in l.lower()]\n",
    "    if len(tgt_lang) == 0:\n",
    "        raise ValueError(f'Target language \"{args.target_language}\" not supported by DeepL.')\n",
    "    if len(tgt_lang) > 1:\n",
    "        raise ValueError(f'Target language \"{args.target_language}\" ambiguous. Please specify one of {tgt_lang}.')\n",
    "    tgt_lang = tgt_lang[0]\n",
    "    src_langs = model.get_languages(target_lang = tgt_lang)\n",
    "\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    try:\n",
    "        df = translate_df(\n",
    "            df=df, \n",
    "            # data frame arguments\n",
    "            text_col=args.text_col,\n",
    "            lang_col=args.lang_col,\n",
    "            target_language=tgt_lang, \n",
    "            target_col=args.target_col if hasattr(args, 'target_col') else f'{args.text_col}_mt_{args.model_name.lower()}',\n",
    "            # translation model arguments\n",
    "            translation_function=model.translate,\n",
    "            supported_languages=src_langs,\n",
    "            batch_size=args.batch_size if hasattr(args, 'batch_size') else 16,\n",
    "            device=model.device,\n",
    "            # arguments forwarded to model.translate()\n",
    "            beam_size=5,\n",
    "            perform_sentence_splitting=False,\n",
    "            show_progress_bar=False, \n",
    "            # print progress bar\n",
    "            verbose=args.verbose,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f'WARNING: Error during translation \"{str(e)}\". Returning data frame with translations so far.')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device \"mps\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5360992bac244985a50210569f3e5318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"deu\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aaed4e988944e01817bef0bc54b53d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"fin\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b50dcb03ac40e79be04a331c84e147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"spa\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take the example sentences from above again (but delete previously translations)\n",
    "if 'text_mt_m2m' in expls.columns:\n",
    "    del expls['text_mt_m2m']\n",
    "\n",
    "# translate\n",
    "expls = translate_df_with_easynmt(\n",
    "    df=expls, \n",
    "    model_name='m2m_100_418M',\n",
    "    # data frame arguments\n",
    "    text_col='text',\n",
    "    lang_col='lang',\n",
    "    target_language='en', \n",
    "    target_col='text_mt_m2m',\n",
    "    batch_size=4, # <== use small batch size for illustration \n",
    "    # arguments forwarded to model.translate()\n",
    "    beam_size=5,\n",
    "    perform_sentence_splitting=False,\n",
    "    show_progress_bar=False, \n",
    "    # print progress bar\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device \"mps\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce607441c5f9423fbae3b161ae55b59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"deu\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbcd92b72ae4dcda862c258b391d924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"fin\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9179d144f9a484287faacb90ad3f6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"spa\":   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take the example sentences from above again (but delete previously translations)\n",
    "if 'text_mt_opus' in expls.columns:\n",
    "    del expls['text_mt_opus']\n",
    "\n",
    "# translate\n",
    "expls = translate_df_with_easynmt(\n",
    "    df=expls, \n",
    "    model_name='opus-mt',\n",
    "    # data frame arguments\n",
    "    text_col='text',\n",
    "    lang_col='lang',\n",
    "    target_language='en', \n",
    "    target_col='text_mt_opus',\n",
    "    batch_size=4, # <== use small batch size for illustration \n",
    "    # arguments forwarded to model.translate()\n",
    "    beam_size=5,\n",
    "    perform_sentence_splitting=False,\n",
    "    show_progress_bar=False, \n",
    "    # print progress bar\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepl\n",
    "\n",
    "def translate_df_with_deepl(df, **kwargs):\n",
    "    args = SimpleNamespace(**kwargs)\n",
    "\n",
    "    # get API key\n",
    "    try:\n",
    "        with open(args.api_key_file) as f:\n",
    "            api_key = f.read().strip()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Could not load API key file \"{args.api_key_file}\". Reason: {str(e)}')\n",
    "        \n",
    "    # initialize a `Translator` instance\n",
    "    try:\n",
    "        translator = deepl.Translator(api_key)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Could not connect to DeepL API. Reason: {str(e)}')\n",
    "\n",
    "    # get source and target languages\n",
    "    src_langs = [l.code.lower() for l in translator.get_source_languages()]\n",
    "    tgt_lang = [l.code.lower() for l in translator.get_target_languages() if args.target_language.lower() == l.code.lower() or args.target_language.lower() in l.code.lower()]\n",
    "    if len(tgt_lang) == 0:\n",
    "        raise ValueError(f'Target language \"{args.target_language}\" not supported by DeepL.')\n",
    "    if len(tgt_lang) > 1:\n",
    "        raise ValueError(f'Target language \"{args.target_language}\" ambiguous. Please specify one of {tgt_lang}.')\n",
    "    tgt_lang = tgt_lang[0]\n",
    "    \n",
    "    df = df.copy(deep=True)\n",
    "    tgt_col = f'{args.text_col}_mt_deepl'\n",
    "    \n",
    "    # translate\n",
    "    try:\n",
    "        df = translate_df(\n",
    "            df=df, \n",
    "            # data frame arguments\n",
    "            text_col=args.text_col,\n",
    "            lang_col=args.lang_col,\n",
    "            target_language=tgt_lang,\n",
    "            target_col=args.target_col if hasattr(args, 'target_col') else tgt_col,\n",
    "            # translation model arguments\n",
    "            translation_function=translator.translate_text,\n",
    "            supported_languages=src_langs,\n",
    "            batch_size=args.batch_size if hasattr(args, 'batch_size') else 1280,\n",
    "            # arguments forwarded to translator.translate_text()\n",
    "            split_sentences='off' if not hasattr(args, 'split_sentences') else 'on' if args.split_sentences else 'off',\n",
    "            # print progress bar\n",
    "            verbose=args.verbose,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f'WARNING: Error during translation \"{str(e)}\". Returning data frame with translations so far.')\n",
    "    \n",
    "    try:\n",
    "        # post-process translation result\n",
    "        df[tgt_col] = df[tgt_col].apply(lambda x: x if isinstance(x, str) else x.text if x is not None else None)\n",
    "    except Exception as e:\n",
    "        print(f'WARNING: Error during post-processing \"{str(e)}\". Returning data frame with translations so far.')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffbf53b73dc4d21b952359132277b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"deu\": 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd43470bc8c1418794c91b4d0c5486a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"fin\": 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928ce8df05aa4433b9ca72bacfa8de82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"spa\": 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# translate\n",
    "expls = translate_df_with_deepl(\n",
    "    df=expls, \n",
    "    api_key_file=os.path.join(os.environ['SPATH'], 'deepl'),\n",
    "    # data frame arguments\n",
    "    text_col='text',\n",
    "    lang_col='lang',\n",
    "    target_language='en-gb', \n",
    "    target_col='text_mt_deepl',\n",
    "    # print progress bar\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import translate_v2 as gt\n",
    "\n",
    "def translate_df_with_google(df, **kwargs):\n",
    "    args = SimpleNamespace(**kwargs)\n",
    "\n",
    "    if hasattr(args, 'batch_size'):\n",
    "        assert args.batch_size <= 128, 'Google Cloud Translation API only supports batch sizes up to 128.'\n",
    "    \n",
    "    # get API key\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(args.api_key_file)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Could not load API key file \"{args.api_key_file}\". Reason: {str(e)}')\n",
    "    \n",
    "    # initialize a `translator` instance\n",
    "    try:\n",
    "        translator = gt.Client(credentials=credentials)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f'Could not connect to Google Cloud Translation API. Reason: {str(e)}')\n",
    "    \n",
    "    # get source and target languages\n",
    "    src_langs = [l['language']  for l in translator.get_languages()]\n",
    "    tgt_lang = [l.lower() for l in src_langs if args.target_language.lower() == l.lower() or args.target_language.lower() in l.lower()]\n",
    "    if len(tgt_lang) == 0:\n",
    "        raise ValueError(f'Target language \"{args.target_language}\" not supported by Google Cloud Trsanslation API.')\n",
    "    if len(tgt_lang) > 1:\n",
    "        raise ValueError(f'Target language \"{args.target_language}\" ambiguous. Please specify one of {tgt_lang}.')\n",
    "    tgt_lang = tgt_lang[0]\n",
    "    \n",
    "    df = df.copy(deep=True)\n",
    "    tgt_col = f'{args.text_col}_mt_google'\n",
    "    \n",
    "    def translate_util(values, target_lang, source_lang, **kwargs):\n",
    "        return translator.translate(values=values, target_language=target_lang, source_language=source_lang, **kwargs)\n",
    "\n",
    "    # translate\n",
    "    try:\n",
    "        df = translate_df(\n",
    "            df=df, \n",
    "            # data frame arguments\n",
    "            text_col=args.text_col,\n",
    "            lang_col=args.lang_col,\n",
    "            target_language=tgt_lang,\n",
    "            target_col=args.target_col if hasattr(args, 'target_col') else tgt_col,\n",
    "            # translation model arguments\n",
    "            translation_function=translate_util,\n",
    "            supported_languages=src_langs,\n",
    "            batch_size=args.batch_size if hasattr(args, 'batch_size') else 128,\n",
    "            # print progress bar\n",
    "            verbose=args.verbose,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f'WARNING: Error during translation \"{str(e)}\". Returning data frame with translations so far.')\n",
    "    \n",
    "    try:\n",
    "        # post-process translation result\n",
    "        df[tgt_col] = df[tgt_col].apply(lambda x: x if isinstance(x, str) else x['translatedText'] if x is not None else None)\n",
    "    except Exception as e:\n",
    "        print(f'WARNING: Error during post-processing \"{str(e)}\". Returning data frame with translations so far.')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6668eef031ae478588cafd644b2c3a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"deu\": 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9826c7621f4d5bbf903408b1e22f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"fin\": 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb95e1fb68742e79fc6ac215030d7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "translating 4 text(s) from \"spa\": 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# translate\n",
    "expls = translate_df_with_google(\n",
    "    df=expls, \n",
    "    api_key_file=os.path.join(os.environ['SPATH'], 'multilingual-gesis-translate.json'),\n",
    "    # data frame arguments\n",
    "    text_col='text',\n",
    "    lang_col='lang',\n",
    "    target_language='en', \n",
    "    target_col='text_mt_google',\n",
    "    # print progress bar\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare translations\n",
    "\n",
    "Ideally, we would want to (i) compare machine translations against human translations and (ii) crowd-source bilingual speakers' assessments of translation quality.\n",
    "But this is beyonds our means and outside the scope of this course.\n",
    "Instead we show some quantitative comparisons of the translations produced by the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualititive comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>text_mt_m2m</th>\n",
       "      <th>text_mt_opus</th>\n",
       "      <th>text_mt_deepl</th>\n",
       "      <th>text_mt_google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa</td>\n",
       "      <td>Los inmigrantes han rejuvenecido nuestra pobla...</td>\n",
       "      <td>Immigrants have rejuvenated our population and...</td>\n",
       "      <td>Immigrants have rejuvenated our population and...</td>\n",
       "      <td>Immigrants have rejuvenated our population and...</td>\n",
       "      <td>Immigrants have rejuvenated our population and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa</td>\n",
       "      <td>así como proyectar la acción del Gobierno en c...</td>\n",
       "      <td>and project the Government’s action in coopera...</td>\n",
       "      <td>as well as project the Government's action in ...</td>\n",
       "      <td>as well as projecting the Government's action ...</td>\n",
       "      <td>as well as projecting the Government&amp;#39;s act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deu</td>\n",
       "      <td>§ Integration fördern</td>\n",
       "      <td>Promote integration</td>\n",
       "      <td>§ Promote integration</td>\n",
       "      <td>§ Promoting integration</td>\n",
       "      <td>§ Promote integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa</td>\n",
       "      <td>Ello requiere una vigilancia mayor y más solid...</td>\n",
       "      <td>This requires greater surveillance and more so...</td>\n",
       "      <td>This requires greater vigilance and greater so...</td>\n",
       "      <td>This requires greater vigilance and more solid...</td>\n",
       "      <td>This requires greater vigilance and more solid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kun keskustelu kiehuu, on vaarana, että huudam...</td>\n",
       "      <td>When the discussion is boiling, there is a dan...</td>\n",
       "      <td>When the debate boils, there is a danger that ...</td>\n",
       "      <td>When the debate boils over, we run the risk of...</td>\n",
       "      <td>When the discussion is heated, there is a dang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deu</td>\n",
       "      <td>Junge Deutsche, die auch noch den Pass eines a...</td>\n",
       "      <td>Young Germans who still have the passport of a...</td>\n",
       "      <td>Young Germans, who also have the passport of a...</td>\n",
       "      <td>Young Germans who also have a passport from an...</td>\n",
       "      <td>Young Germans who also have a passport from an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deu</td>\n",
       "      <td>Die von den Kantonen und Gemeinden eingerichte...</td>\n",
       "      <td>The existing offers of courses and employment ...</td>\n",
       "      <td>The existing courses and employment programmes...</td>\n",
       "      <td>The existing courses and employment programmes...</td>\n",
       "      <td>The existing courses and employment programs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa</td>\n",
       "      <td>Apoyaremos de manera decidida las iniciativas ...</td>\n",
       "      <td>We will strongly support co-development initia...</td>\n",
       "      <td>We will strongly support co-development initia...</td>\n",
       "      <td>We will strongly support co-development initia...</td>\n",
       "      <td>We will decisively support co-development init...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fin</td>\n",
       "      <td>On tärkeää ymmärtää maahanmuuton syitä ja muut...</td>\n",
       "      <td>It is important to understand the causes of mi...</td>\n",
       "      <td>It is important to understand the causes of im...</td>\n",
       "      <td>It is important to understand the causes of mi...</td>\n",
       "      <td>It is important to understand the reasons for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fin</td>\n",
       "      <td>Maahanmuuttaja- ja romaniperheiden lapsia tule...</td>\n",
       "      <td>Children from immigrants and Romans should be ...</td>\n",
       "      <td>Children of immigrant and Roma families should...</td>\n",
       "      <td>Children from immigrant and Roma families shou...</td>\n",
       "      <td>Children from immigrant and Roma families shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deu</td>\n",
       "      <td>Wir wollen zudem die Ausbildungs- und Arbeitsv...</td>\n",
       "      <td>We also want to eliminate the education and em...</td>\n",
       "      <td>We also want to eliminate the bans on training...</td>\n",
       "      <td>We also want to remove the training and work b...</td>\n",
       "      <td>We also want to eliminate the training and wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fin</td>\n",
       "      <td>Kristillisdemokraatit haastavat suomalaiset ka...</td>\n",
       "      <td>Christian Democrats challenge the Finnish to g...</td>\n",
       "      <td>Christian Democrats challenge Finns to grow in...</td>\n",
       "      <td>Christian Democrats challenge Finns to grow in...</td>\n",
       "      <td>The Christian Democrats challenge Finns to gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang                                               text  \\\n",
       "0   spa  Los inmigrantes han rejuvenecido nuestra pobla...   \n",
       "1   spa  así como proyectar la acción del Gobierno en c...   \n",
       "2   deu                              § Integration fördern   \n",
       "3   spa  Ello requiere una vigilancia mayor y más solid...   \n",
       "4   fin  Kun keskustelu kiehuu, on vaarana, että huudam...   \n",
       "5   deu  Junge Deutsche, die auch noch den Pass eines a...   \n",
       "6   deu  Die von den Kantonen und Gemeinden eingerichte...   \n",
       "7   spa  Apoyaremos de manera decidida las iniciativas ...   \n",
       "8   fin  On tärkeää ymmärtää maahanmuuton syitä ja muut...   \n",
       "9   fin  Maahanmuuttaja- ja romaniperheiden lapsia tule...   \n",
       "10  deu  Wir wollen zudem die Ausbildungs- und Arbeitsv...   \n",
       "11  fin  Kristillisdemokraatit haastavat suomalaiset ka...   \n",
       "\n",
       "                                          text_mt_m2m  \\\n",
       "0   Immigrants have rejuvenated our population and...   \n",
       "1   and project the Government’s action in coopera...   \n",
       "2                                 Promote integration   \n",
       "3   This requires greater surveillance and more so...   \n",
       "4   When the discussion is boiling, there is a dan...   \n",
       "5   Young Germans who still have the passport of a...   \n",
       "6   The existing offers of courses and employment ...   \n",
       "7   We will strongly support co-development initia...   \n",
       "8   It is important to understand the causes of mi...   \n",
       "9   Children from immigrants and Romans should be ...   \n",
       "10  We also want to eliminate the education and em...   \n",
       "11  Christian Democrats challenge the Finnish to g...   \n",
       "\n",
       "                                         text_mt_opus  \\\n",
       "0   Immigrants have rejuvenated our population and...   \n",
       "1   as well as project the Government's action in ...   \n",
       "2                               § Promote integration   \n",
       "3   This requires greater vigilance and greater so...   \n",
       "4   When the debate boils, there is a danger that ...   \n",
       "5   Young Germans, who also have the passport of a...   \n",
       "6   The existing courses and employment programmes...   \n",
       "7   We will strongly support co-development initia...   \n",
       "8   It is important to understand the causes of im...   \n",
       "9   Children of immigrant and Roma families should...   \n",
       "10  We also want to eliminate the bans on training...   \n",
       "11  Christian Democrats challenge Finns to grow in...   \n",
       "\n",
       "                                        text_mt_deepl  \\\n",
       "0   Immigrants have rejuvenated our population and...   \n",
       "1   as well as projecting the Government's action ...   \n",
       "2                             § Promoting integration   \n",
       "3   This requires greater vigilance and more solid...   \n",
       "4   When the debate boils over, we run the risk of...   \n",
       "5   Young Germans who also have a passport from an...   \n",
       "6   The existing courses and employment programmes...   \n",
       "7   We will strongly support co-development initia...   \n",
       "8   It is important to understand the causes of mi...   \n",
       "9   Children from immigrant and Roma families shou...   \n",
       "10  We also want to remove the training and work b...   \n",
       "11  Christian Democrats challenge Finns to grow in...   \n",
       "\n",
       "                                       text_mt_google  \n",
       "0   Immigrants have rejuvenated our population and...  \n",
       "1   as well as projecting the Government&#39;s act...  \n",
       "2                               § Promote integration  \n",
       "3   This requires greater vigilance and more solid...  \n",
       "4   When the discussion is heated, there is a dang...  \n",
       "5   Young Germans who also have a passport from an...  \n",
       "6   The existing courses and employment programs f...  \n",
       "7   We will decisively support co-development init...  \n",
       "8   It is important to understand the reasons for ...  \n",
       "9   Children from immigrant and Roma families shou...  \n",
       "10  We also want to eliminate the training and wor...  \n",
       "11  The Christian Democrats challenge Finns to gro...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Jaccard similarity measure, defined as \n",
    "\n",
    "$$\n",
    "Jac(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "\n",
    "where \n",
    "- $A$ is the set of words in the sentence $a$ and $B$ is the set of words in sentence $b$,\n",
    "- $|A \\cap B|$ measures intersection of words (i.e., words that are in both sentences), and\n",
    "- $|A \\cup B|$ measures the union of words (i.e., words that are in either sentence).\n",
    "\n",
    "**_Note:_** we could also more specialized metrics like [BLEU](https://en.wikipedia.org/wiki/BLEU) or [METEOR](https://en.wikipedia.org/wiki/METEOR) that are specifically designed for machine translation evaluation (read more [here](https://www.machinetranslation.com/blog/machine-translation-evaluation-ultimate-guide)). But we have no gold standard translations here, so we stick to the Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard similarity = 0.720\n",
      "\n",
      "spa: Los inmigrantes han rejuvenecido nuestra población y han contribuido al periodo de prosperidad económica más importante de este comienzo de siglo.\n",
      "m2m: Immigrants have rejuvenated our population and have contributed to the most important period of economic prosperity of this beginning of the century.\n",
      "deepl: Immigrants have rejuvenated our population and contributed to the most important period of economic prosperity at the beginning of this century.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.611\n",
      "\n",
      "fin: Kristillisdemokraatit haastavat suomalaiset kasvamaan muualta muuttaneiden ihmisten hyväksymisessä\n",
      "m2m: Christian Democrats challenge the Finnish to grow in acceptance of people who have moved elsewhere\n",
      "deepl: Christian Democrats challenge Finns to grow in accepting people who have moved from elsewhere\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.531\n",
      "\n",
      "fin: On tärkeää ymmärtää maahanmuuton syitä ja muuttajien haasteita, etteivät kielteiset ilmiöt saa kasvualustaa.\n",
      "m2m: It is important to understand the causes of migration and the challenges of migrants, so that negative phenomena do not get the basis for growth.\n",
      "deepl: It is important to understand the causes of migration and the challenges faced by migrants, so that negative phenomena are not allowed to grow.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.529\n",
      "\n",
      "fin: Maahanmuuttaja- ja romaniperheiden lapsia tulee kannustaa osallistumaan esiopetukseen.\n",
      "m2m: Children from immigrants and Romans should be encouraged to participate in pre-education.\n",
      "deepl: Children from immigrant and Roma families should be encouraged to participate in pre-school education.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.523\n",
      "\n",
      "deu: Junge Deutsche, die auch noch den Pass eines anderen Staates haben, müssen die deutsche Staatsbürgerschaft behalten dürfen, auch wenn sie nach ihrem 23. Geburtstag die andere Staatsangehörigkeit nicht aufgeben wollen.\n",
      "m2m: Young Germans who still have the passport of another state must be allowed to retain German citizenship even if they do not want to give up the other citizenship after their 23th birthday.\n",
      "deepl: Young Germans who also have a passport from another country must be allowed to keep their German citizenship, even if they do not want to give up their other nationality after their 23rd birthday.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.523\n",
      "\n",
      "spa: Apoyaremos de manera decidida las iniciativas de codesarrollo, contribuyendo a que los inmigrantes que voluntariamente lo deseen puedan destinar parte de sus ingresos a inversiones productivas y creación de empresas en sus países de origen.\n",
      "m2m: We will strongly support co-development initiatives, contributing to the fact that immigrants who voluntarily wish to do so can allocate part of their income to productive investments and the creation of in their country of origin.\n",
      "deepl: We will strongly support co-development initiatives, helping immigrants who voluntarily wish to do so to allocate part of their income to productive investments and business start-ups in their countries of origin.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.500\n",
      "\n",
      "spa: Ello requiere una vigilancia mayor y más solidaridad con todos estos colectivos y muy especialmente con las mujeres inmigrantes para evitar que su condición de mujeres agrave su ya difícil situación.\n",
      "m2m: This requires greater surveillance and more solidarity with all these collectives and very especially with women immigrants to prevent their status of women from worsening their already difficult situation.\n",
      "deepl: This requires greater vigilance and more solidarity with all these groups and especially with immigrant women to prevent their status as women from aggravating their already difficult situation.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.487\n",
      "\n",
      "deu: Die von den Kantonen und Gemeinden eingerichteten bestehenden Angebote an Kursen und Beschäftigungsprogrammen für Asylbewerberinnen und –bewerber müssen vom Bund beurteilt werden, um die „guten Praktiken“ auszuweiten.\n",
      "m2m: The existing offers of courses and employment programs for asylum seekers established by the cantons and municipalities must be assessed by the Federation in order to expand the “good practices”.\n",
      "deepl: The existing courses and employment programmes for asylum seekers set up by the cantons and municipalities must be assessed by the Confederation in order to expand \"good practices\".\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.406\n",
      "\n",
      "spa: así como proyectar la acción del Gobierno en cooperación al desarrollo mediante la formación académica en países de nuestro entorno geográfico o de tradicional influencia.\n",
      "m2m: and project the Government’s action in cooperation to development through academic training in countries of our geographical or traditional influence environment.\n",
      "deepl: as well as projecting the Government's action in development cooperation through academic training in countries in our geographical environment or those with traditional influence.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.368\n",
      "\n",
      "deu: Wir wollen zudem die Ausbildungs- und Arbeitsverbote für Asylsuchende beseitigen\n",
      "m2m: We also want to eliminate the education and employment ban on asylum seekers.\n",
      "deepl: We also want to remove the training and work bans for asylum seekers\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.250\n",
      "\n",
      "deu: § Integration fördern\n",
      "m2m: Promote integration\n",
      "deepl: § Promoting integration\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.196\n",
      "\n",
      "fin: Kun keskustelu kiehuu, on vaarana, että huudamme omaa mielipidettämme niin kovaa, ettemme malta enää kuunnella toista.\n",
      "m2m: When the discussion is boiling, there is a danger that we will scream our own opinion so loud that we will no longer be able to listen to another.\n",
      "deepl: When the debate boils over, we run the risk of shouting our own opinions so loudly that we can't bear to listen to the other person.\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can compare translations similarities\n",
    "\n",
    "def jaccard_set(list1, list2):\n",
    "    \"\"\"\n",
    "    Define Jaccard Similarity function for two sets\n",
    "\n",
    "    source: https://www.learndatasci.com/glossary/jaccard-similarity/\n",
    "    \"\"\"\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "expls['jsim'] = expls[['text_mt_m2m', 'text_mt_deepl']].apply(lambda x: jaccard_set(x.iloc[0].split(' '), x.iloc[1].split(' ')), axis=1)\n",
    "for i, d in expls.sort_values('jsim', ascending=False).iterrows():\n",
    "    print(f'jaccard similarity = {d.jsim:.03f}\\n')\n",
    "    print(f'{d.lang}: {d.text}')\n",
    "    print(f'm2m: {d.text_mt_m2m}')\n",
    "    print(f'deepl: {d.text_mt_deepl}')\n",
    "    print('---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary of all pairwise comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "cols = ['text_mt_m2m', 'text_mt_opus', 'text_mt_google', 'text_mt_deepl']\n",
    "# compute all pairs of values in `cols``\n",
    "pairs = combinations(cols, 2)\n",
    "\n",
    "jsims = {}\n",
    "for a, b in pairs:\n",
    "    vals = expls[[a, b]].apply(lambda x: jaccard_set(x.iloc[0].split(' '), x.iloc[1].split(' ')), axis=1)\n",
    "    key = f'jsim_{a.split(\"_\")[-1]}_{b.split(\"_\")[-1]}'\n",
    "    jsims[key] = {}\n",
    "    for (l, m), s in zip(vals.groupby(expls.lang).mean().to_dict().items(), vals.groupby(expls.lang).std().to_list()):\n",
    "        jsims[key][l] = {'mean': m, 'std': s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deu</th>\n",
       "      <th>fin</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jsim_m2m_opus</th>\n",
       "      <td>0.554±0.103</td>\n",
       "      <td>0.546±0.179</td>\n",
       "      <td>0.559±0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_m2m_google</th>\n",
       "      <td>0.575±0.094</td>\n",
       "      <td>0.548±0.099</td>\n",
       "      <td>0.545±0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_m2m_deepl</th>\n",
       "      <td>0.407±0.124</td>\n",
       "      <td>0.467±0.185</td>\n",
       "      <td>0.537±0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_opus_google</th>\n",
       "      <td>0.793±0.200</td>\n",
       "      <td>0.629±0.213</td>\n",
       "      <td>0.599±0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_opus_deepl</th>\n",
       "      <td>0.641±0.123</td>\n",
       "      <td>0.585±0.286</td>\n",
       "      <td>0.634±0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_google_deepl</th>\n",
       "      <td>0.671±0.160</td>\n",
       "      <td>0.560±0.286</td>\n",
       "      <td>0.678±0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           deu          fin          spa\n",
       "jsim_m2m_opus      0.554±0.103  0.546±0.179  0.559±0.143\n",
       "jsim_m2m_google    0.575±0.094  0.548±0.099  0.545±0.108\n",
       "jsim_m2m_deepl     0.407±0.124  0.467±0.185  0.537±0.132\n",
       "jsim_opus_google   0.793±0.200  0.629±0.213  0.599±0.081\n",
       "jsim_opus_deepl    0.641±0.123  0.585±0.286  0.634±0.087\n",
       "jsim_google_deepl  0.671±0.160  0.560±0.286  0.678±0.042"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(jsims).apply(lambda x: x.apply(lambda y: f\"{y['mean']:.03f}±{y['std']:.03f}\")).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this metric (and our very low sample size), Google compares only slightly better to DeepL than OPUS-MT –- but  also depends on the language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with token-based metrics like Jaccard is that they do not account for the semantic similarity of sentences.\n",
    "So let's use sentence embeddings to evaluate translations \"semantic\" similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compare translations similarities with sentence embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302455"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'The existing offers of courses and employment programs for asylum seekers established by the cantons and municipalities must be assessed by the Federation in order to expand the “good practices”.'\n",
    "sent2 = 'The existing courses and employment programmes for asylum seekers set up by the cantons and municipalities must be assessed by the Confederation in order to expand \"good practices\".'\n",
    "\n",
    "embeddings = sentence_transformer.encode([sent1, sent2])\n",
    "\n",
    "# compute the similarity between the two sentences\n",
    "\n",
    "cosine_similarity(embeddings)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard similarity = 0.997\n",
      "\n",
      "spa: Los inmigrantes han rejuvenecido nuestra población y han contribuido al periodo de prosperidad económica más importante de este comienzo de siglo.\n",
      "m2m: Immigrants have rejuvenated our population and have contributed to the most important period of economic prosperity of this beginning of the century.\n",
      "deepl: Immigrants have rejuvenated our population and contributed to the most important period of economic prosperity at the beginning of this century.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.975\n",
      "\n",
      "spa: Apoyaremos de manera decidida las iniciativas de codesarrollo, contribuyendo a que los inmigrantes que voluntariamente lo deseen puedan destinar parte de sus ingresos a inversiones productivas y creación de empresas en sus países de origen.\n",
      "m2m: We will strongly support co-development initiatives, contributing to the fact that immigrants who voluntarily wish to do so can allocate part of their income to productive investments and the creation of in their country of origin.\n",
      "deepl: We will strongly support co-development initiatives, helping immigrants who voluntarily wish to do so to allocate part of their income to productive investments and business start-ups in their countries of origin.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.949\n",
      "\n",
      "fin: On tärkeää ymmärtää maahanmuuton syitä ja muuttajien haasteita, etteivät kielteiset ilmiöt saa kasvualustaa.\n",
      "m2m: It is important to understand the causes of migration and the challenges of migrants, so that negative phenomena do not get the basis for growth.\n",
      "deepl: It is important to understand the causes of migration and the challenges faced by migrants, so that negative phenomena are not allowed to grow.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.946\n",
      "\n",
      "deu: Junge Deutsche, die auch noch den Pass eines anderen Staates haben, müssen die deutsche Staatsbürgerschaft behalten dürfen, auch wenn sie nach ihrem 23. Geburtstag die andere Staatsangehörigkeit nicht aufgeben wollen.\n",
      "m2m: Young Germans who still have the passport of another state must be allowed to retain German citizenship even if they do not want to give up the other citizenship after their 23th birthday.\n",
      "deepl: Young Germans who also have a passport from another country must be allowed to keep their German citizenship, even if they do not want to give up their other nationality after their 23rd birthday.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.930\n",
      "\n",
      "deu: Die von den Kantonen und Gemeinden eingerichteten bestehenden Angebote an Kursen und Beschäftigungsprogrammen für Asylbewerberinnen und –bewerber müssen vom Bund beurteilt werden, um die „guten Praktiken“ auszuweiten.\n",
      "m2m: The existing offers of courses and employment programs for asylum seekers established by the cantons and municipalities must be assessed by the Federation in order to expand the “good practices”.\n",
      "deepl: The existing courses and employment programmes for asylum seekers set up by the cantons and municipalities must be assessed by the Confederation in order to expand \"good practices\".\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.915\n",
      "\n",
      "deu: Wir wollen zudem die Ausbildungs- und Arbeitsverbote für Asylsuchende beseitigen\n",
      "m2m: We also want to eliminate the education and employment ban on asylum seekers.\n",
      "deepl: We also want to remove the training and work bans for asylum seekers\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.899\n",
      "\n",
      "fin: Kristillisdemokraatit haastavat suomalaiset kasvamaan muualta muuttaneiden ihmisten hyväksymisessä\n",
      "m2m: Christian Democrats challenge the Finnish to grow in acceptance of people who have moved elsewhere\n",
      "deepl: Christian Democrats challenge Finns to grow in accepting people who have moved from elsewhere\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.854\n",
      "\n",
      "spa: Ello requiere una vigilancia mayor y más solidaridad con todos estos colectivos y muy especialmente con las mujeres inmigrantes para evitar que su condición de mujeres agrave su ya difícil situación.\n",
      "m2m: This requires greater surveillance and more solidarity with all these collectives and very especially with women immigrants to prevent their status of women from worsening their already difficult situation.\n",
      "deepl: This requires greater vigilance and more solidarity with all these groups and especially with immigrant women to prevent their status as women from aggravating their already difficult situation.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.853\n",
      "\n",
      "spa: así como proyectar la acción del Gobierno en cooperación al desarrollo mediante la formación académica en países de nuestro entorno geográfico o de tradicional influencia.\n",
      "m2m: and project the Government’s action in cooperation to development through academic training in countries of our geographical or traditional influence environment.\n",
      "deepl: as well as projecting the Government's action in development cooperation through academic training in countries in our geographical environment or those with traditional influence.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.849\n",
      "\n",
      "fin: Maahanmuuttaja- ja romaniperheiden lapsia tulee kannustaa osallistumaan esiopetukseen.\n",
      "m2m: Children from immigrants and Romans should be encouraged to participate in pre-education.\n",
      "deepl: Children from immigrant and Roma families should be encouraged to participate in pre-school education.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.815\n",
      "\n",
      "fin: Kun keskustelu kiehuu, on vaarana, että huudamme omaa mielipidettämme niin kovaa, ettemme malta enää kuunnella toista.\n",
      "m2m: When the discussion is boiling, there is a danger that we will scream our own opinion so loud that we will no longer be able to listen to another.\n",
      "deepl: When the debate boils over, we run the risk of shouting our own opinions so loudly that we can't bear to listen to the other person.\n",
      "---\n",
      "\n",
      "jaccard similarity = 0.775\n",
      "\n",
      "deu: § Integration fördern\n",
      "m2m: Promote integration\n",
      "deepl: § Promoting integration\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def embedding_similarity(sent1, sent2):\n",
    "    embeddings = sentence_transformer.encode([sent1, sent2])\n",
    "    return cosine_similarity(embeddings)[0,1]\n",
    "\n",
    "expls['esim'] = expls[['text_mt_m2m', 'text_mt_deepl']].apply(lambda x: embedding_similarity(x.iloc[0], x.iloc[1]), axis=1)\n",
    "for i, d in expls.sort_values('esim', ascending=False).iterrows():\n",
    "    print(f'jaccard similarity = {d.esim:.03f}\\n')\n",
    "    print(f'{d.lang}: {d.text}')\n",
    "    print(f'm2m: {d.text_mt_m2m}')\n",
    "    print(f'deepl: {d.text_mt_deepl}')\n",
    "    print('---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "cols = ['text_mt_m2m', 'text_mt_opus', 'text_mt_google', 'text_mt_deepl']\n",
    "pairs = combinations(cols, 2)\n",
    "\n",
    "esims = {}\n",
    "for a, b in pairs:\n",
    "    vals = expls[[a, b]].apply(lambda x: embedding_similarity(x.iloc[0], x.iloc[1]), axis=1)\n",
    "    key = f'jsim_{a.split(\"_\")[-1]}_{b.split(\"_\")[-1]}'\n",
    "    esims[key] = {}\n",
    "    for (l, m), s in zip(vals.groupby(expls.lang).mean().to_dict().items(), vals.groupby(expls.lang).std().to_list()):\n",
    "        esims[key][l] = {'mean': m, 'std': s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deu</th>\n",
       "      <th>fin</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jsim_m2m_opus</th>\n",
       "      <td>0.910±0.083</td>\n",
       "      <td>0.867±0.033</td>\n",
       "      <td>0.935±0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_m2m_google</th>\n",
       "      <td>0.914±0.084</td>\n",
       "      <td>0.834±0.077</td>\n",
       "      <td>0.912±0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_m2m_deepl</th>\n",
       "      <td>0.892±0.079</td>\n",
       "      <td>0.878±0.058</td>\n",
       "      <td>0.920±0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_opus_google</th>\n",
       "      <td>0.990±0.008</td>\n",
       "      <td>0.915±0.077</td>\n",
       "      <td>0.947±0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_opus_deepl</th>\n",
       "      <td>0.966±0.014</td>\n",
       "      <td>0.936±0.067</td>\n",
       "      <td>0.960±0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jsim_google_deepl</th>\n",
       "      <td>0.966±0.020</td>\n",
       "      <td>0.897±0.070</td>\n",
       "      <td>0.978±0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           deu          fin          spa\n",
       "jsim_m2m_opus      0.910±0.083  0.867±0.033  0.935±0.069\n",
       "jsim_m2m_google    0.914±0.084  0.834±0.077  0.912±0.084\n",
       "jsim_m2m_deepl     0.892±0.079  0.878±0.058  0.920±0.077\n",
       "jsim_opus_google   0.990±0.008  0.915±0.077  0.947±0.059\n",
       "jsim_opus_deepl    0.966±0.014  0.936±0.067  0.960±0.058\n",
       "jsim_google_deepl  0.966±0.020  0.897±0.070  0.978±0.019"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(esims).apply(lambda x: x.apply(lambda y: f\"{y['mean']:.03f}±{y['std']:.03f}\")).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this metric, OPUS-MT compares as well to DeepL as Google.\n",
    "But mind our small sample size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilingual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
