---
title: "Equivalent_data_selection"
author: "Fabienne Lind"
date: "2023-02-12"
output: html_document
---

# Automated Article Selection and Validation

### Data

In this tasks, we will create and validate search strings for different languages and cases.
I pre-selected data in three language for multiple outlets by using a very broad search string. It included only one keyword per language: 

en: "climate"
de: "klima"
fr: "climatique"

Such a broadly defined search string allows to validate a more specific search string. 
Let's load the data first and take a look. Each row represents one news article.

```{r}

articles <- read.csv("https://raw.githubusercontent.com/fabiennelind/Going-Cross-Lingual_Course/main/data/climate_news.csv")

```



The data includes data for several countries. Select at least two subsets according to your comparative research question.

```{r}
colnames(articles)
articles_uk_en <- subset(articles, Country == "UK")
articles_switzerland_de <- subset(articles, Country == "Switzerland" & Language == "de")
articles_switzerland_fr <- subset(articles, Country == "Switzerland" & Language == "fr")

```


## Automated Data Selection with a Search String per Language

From our universe of articles (all mentioning climate) we like to select only those articles that address climate activism. As a first step, we define the concept more narrowly.

### Concept Definition

**Climate activism** is here defined as XXX 

We intend to measure the salience of climate activism as simple binary variable:
1 = Climate activism is mentioned
0 = No climate activism is mentioned.

### Search string creation

A search string is a set of keywords or phrases that represents the concept of interest. 

We now start collecting relevant keywords for the search strings. We start with a list of keywords that we consider most relevant. 
For clarity, we here work with several keyword sets: we collect the keywords related to country A in two vectors (here named `climate_act_A_de` & `climate_act_A_fr`), and keywords related to  country B in another vector (here named `climate_act_B_en`). 

The keywords are written as regular expressions. A ‘regular expression’ is a pattern that describes a string. To learn more about regular expressions, we recommend this R tutorial [(Wickham & Grolemund, 2017)](https://r4ds.had.co.nz/strings.html). To test regular expressions quickly, visit https://spannbaueradam.shinyapps.io/r_regex_tester/

The following code is only for illustration. Add and modify according to your definition.

```{r}

# English for UK
climate_act_B_en <- c("climate protest", "activists", "greta", "fridays for future")

# German for Switzerland
climate_act_A_de <- c("klimaprotest", "aktivisten")

# French for Switzerland
climate_act_A_fr <- c("protestation climatique", "activistes")

```


All vector names are then saved as vectors.

```{r}

dict_name_B_en <- c("climate_act_B_en") 
dict_name_A_de <- c("climate_act_A_de") 
dict_name_A_fr <- c("climate_act_A_fr") 

```

Before we search the keyword in the text, we apply some pre-processing steps to the text. For this exercise, we designed the keywords all in lower case, so the texts have to be lower case too.

```{r}

articles_uk_en$text <- tolower(articles_uk_en$text) # convert text to lower case
articles_switzerland_de$text <- tolower(articles_switzerland_de$text) # convert text to lower case
articles_switzerland_fr$text <- tolower(articles_switzerland_fr$text) # convert text to lower case

```

We now search the keywords in the article texts. The function `stri_count_regex` from the R package **stringr** can count how often a pattern appears in a text. We call this here the number of hits. The function can search for regular expression. We here ask to count a pattern in the column `text` of the dataframe `articles_uk_en`. 


```{r}

#install.packages("stringi")
library(stringi)

n <- length(dict_name_B_en) # number of keyword sets (each is counted separately)
codings <- vector("list", n) # create an empty list, to be filled in the loop

for (i in dict_name_B_en) {# each keyword set stored in vector 'dict name' is looked at separately
  print(i)
  match <- stri_count_regex(articles_uk_en$text, paste(get(i), collapse='|'))
  codings[[i]] <- data.frame(name=match)
}

codings <- codings[-c(1:n)] # save the relevant part of the list 
codings_df <- do.call("cbind", codings) # unlist

```

Some recoding to get the column names correct.

```{r}

# replace names in resulting data frame with names from dict_name 
cols <- names(codings_df) == "name" # vector with all names in resulting data frame
names(codings_df)[cols] <- paste0("name", seq.int(sum(cols))) # add a number behind each colnumn (to make them differ, necessary for next step)
oldnames <- colnames(codings_df) # a vector with the names of dict
newnames <- names(codings) # a vector with names stored in list

#install.packages("data.table")
library(data.table)
setnames(codings_df, old = oldnames, new = newnames)# finally replace the current names with the correct ones

```

We now add the number of hits counted by the search string (saved in the dataframe `codings_df`) to the articles (the object `articles_uk_en`). Since we did not shuffle the order of rows, we can bind both data frames together with the function `bind_cols`. We create a new dataframe with headlines, article meta-data and codings.

```{r}

#install.packages("dplyr")
library(dplyr)
articles_uk_en_hits <- bind_cols(articles_uk_en, codings_df)
colnames(articles_uk_en_hits)

```

How can we see the headlines for which the dictionary counted a hit?  

```{r}

testa <- subset(articles_uk_en_hits, climate_act_B_en >=1)
head(testa$Headline) 


```

So far, we obtained a count, that represents how often the keywords were detected per text. Since we  initially proposed a simple binary measurement, we now do some recoding. 

We add a new column to the dataframe called `climate_activism`. This column includes a 1 if at least one of all defined keywords creates a hit, and a 0 if no keyword was found. 

```{r}

articles_uk_en_hits$climate_activism <- case_when(articles_uk_en_hits$climate_act_B_en >= 1  ~ 1)# | means or. 
articles_uk_en_hits <- articles_uk_en_hits %>% mutate(climate_activism = if_else(is.na(climate_activism), 0, climate_activism)) # set NA to 0 

```

According to our automated measurement, how many articles deal with climate activism for country B?

```{r}


```



Repeat the search string application now for the other languages and countries. Store the result in a column called 'climate_activism' for each case/language.



Let's start with the German articles in Switzerland.

```{r}


```


Let's continue with the French articles in Switzerland.

```{r}



```

Let's save the result

```{r}

setwd("")
write.csv(articles_hits, "climate_news_d_annotated.csv", row.names = F)

```



We have now managed to get an automated measurement for the variable. **But how valid is this measurement?** Does our small set of keywords represent the concept adequately?

A common procedure in automated content analysis is to test construct validity. We ask:
How close is this automated measurement to a more trusted measurement: Human understanding of text.

We will see how this can be put into practice when we discuss output evaluation. 



