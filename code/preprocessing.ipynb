{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and pre-processing\n",
    "\n",
    "| Authors | Last update |\n",
    "|:------ |:----------- |\n",
    "| Hauke Licht (https://github.com/haukelicht) | 2023-12-02 |\n",
    "\n",
    "<br>\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/fabiennelind/Going-Cross-Lingual_Course/blob/main/code/preprocessing.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We load generally used libraries here and load the rest on the fly in the respedtive sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word tokenization\n",
    "\n",
    "When applying bag-of-words methods to our data, we need to split the text into tokens. \n",
    "\n",
    "The most two popular libraries to handle this that have relatively broad multilingual support are `nltk` and `stanza`\n",
    "\n",
    "**_Note:_** Another library that can tokenize and has [wide language support](https://spacy.io/usage/models#languages) is `spacy` (see [here](https://spacy.io/usage/models) how to use it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nltk`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hlicht/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizers', 'corpora']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(nltk.data.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['punkt', 'punkt.zip']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(nltk.data.path[0], 'tokenizers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greek.pickle',\n",
       " 'estonian.pickle',\n",
       " 'turkish.pickle',\n",
       " '.DS_Store',\n",
       " 'polish.pickle',\n",
       " 'PY3',\n",
       " 'russian.pickle',\n",
       " 'czech.pickle',\n",
       " 'portuguese.pickle',\n",
       " 'README',\n",
       " 'dutch.pickle',\n",
       " 'norwegian.pickle',\n",
       " 'malayalam.pickle',\n",
       " 'slovene.pickle',\n",
       " 'english.pickle',\n",
       " 'danish.pickle',\n",
       " 'finnish.pickle',\n",
       " 'swedish.pickle',\n",
       " 'spanish.pickle',\n",
       " 'german.pickle',\n",
       " 'italian.pickle',\n",
       " 'french.pickle']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(nltk.data.path[0], 'tokenizers', 'punkt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(nltk.data.path[0], 'tokenizers', 'punkt')\n",
    "nltk_tokenizer_language_support = [f.replace('.pickle', '') for f in os.listdir(fp) if f.endswith('.pickle')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greek': 'gre',\n",
       " 'estonian': 'est',\n",
       " 'turkish': 'tur',\n",
       " 'polish': 'pol',\n",
       " 'russian': 'rus',\n",
       " 'czech': 'cze',\n",
       " 'portuguese': 'por',\n",
       " 'dutch': 'dut',\n",
       " 'norwegian': 'nor',\n",
       " 'malayalam': 'mal',\n",
       " 'slovene': 'slv',\n",
       " 'english': 'eng',\n",
       " 'danish': 'dan',\n",
       " 'finnish': 'fin',\n",
       " 'swedish': 'swe',\n",
       " 'spanish': 'spa',\n",
       " 'german': 'ger',\n",
       " 'italian': 'ita',\n",
       " 'french': 'fre'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import iso639\n",
    "\n",
    "{l: iso639.to_iso639_2(l) for l in nltk_tokenizer_language_support}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = \"\"\"\n",
    "greek\tgre\tÎ— ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Ï„Î·Ï‚ Î±Î½Î¸ÏÏÏ€Î¹Î½Î·Ï‚ Ï†ÏÏƒÎ·Ï‚ ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î±Ï„Î­Î»ÎµÎ¹Ï‰Ï„Î· Ï€ÎµÏÎ¹Ï€Î­Ï„ÎµÎ¹Î± Ï€Î¿Ï… Î¼Î±Ï‚ ÎºÎ±Î¸Î¿Î´Î·Î³ÎµÎ¯ ÏƒÎµ Î½Î­ÎµÏ‚ ÎµÎ½Î½Î¿Î¹Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î­Ï‚.\n",
    "estonian\test\tEesti rannikul jalutades vÃµib tunnetada mere lÃµpmatust ja ajalooliste jutustuste rikkust.\n",
    "turkish\ttur\tAnadolu'nun mistik atmosferi, tarih ve kÃ¼ltÃ¼rÃ¼n harmanlandÄ±ÄŸÄ± bir yerdir.\n",
    "polish\tpol\tCiekawoÅ›Ä‡ i odkrywanie nowych koncepcji stanowiÄ… fundament naszej ludzkiej egzystencji.\n",
    "russian\trus\tĞ ÑƒÑÑĞºĞ°Ñ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´ Ğ½Ğ°Ğ¼Ğ¸ Ğ±Ğ¾Ğ³Ğ°Ñ‚ÑÑ‚Ğ²Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ¸ Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ½Ğ°Ñ Ğ² Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ Ğ´ÑƒÑˆĞ¸.\n",
    "czech\tcze\tÄŒeskÃ¡ krajina oplÃ½vÃ¡ malebnÃ½mi zÃ¡koutÃ­mi a historickÃ½mi pamÃ¡tkami, kterÃ© vyprÃ¡vÄ›jÃ­ pÅ™Ã­bÄ›hy minulosti.\n",
    "portuguese\tpor\tA diversidade cultural do Brasil reflete-se na fusÃ£o de influÃªncias indÃ­genas, africanas e europeias, criando uma rica tapeÃ§aria de tradiÃ§Ãµes.\n",
    "dutch\tdut\tDe grachten van Amsterdam getuigen van een rijke geschiedenis en vormen een intrigerend netwerk dat de stad doorkruist.\n",
    "norwegian\tnor\tNorges majestetiske fjorder og bortgjemte fjelltopper lokker eventyrlystne reisende til Ã¥ utforske naturens underverker.\n",
    "malayalam\tmal\tà´•àµ‡à´°à´³à´¤àµà´¤à´¿à´¨àµà´±àµ† à´¸àµ—à´¨àµà´¦à´°àµà´¯à´‚ à´ªàµà´°à´•à´Ÿà´®à´¾à´•àµà´•àµà´¨àµà´¨ à´…à´•àµà´•à´¾à´¦à´®à´¿à´• à´ªà´°à´¿à´¸àµà´¥à´¿à´¤à´¿à´•àµ¾ à´¹à´¿à´®à´¾à´²à´¯à´¤àµà´¤à´¿à´¨àµà´±àµ† à´¸à´¨àµà´¦àµ¼à´¶à´¨à´¤àµà´¤à´¿à´¨àµ à´•àµ‡à´¨àµà´¦àµà´°àµ€à´•à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ.\n",
    "slovene\tslv\tSlovenski jezik je bogat s svojimi idiomatskimi izrazi, ki odraÅ¾ajo duhovito naravo in globoko Äustvenost.\n",
    "english\teng\tDelving into the intricacies of quantum mechanics allows us to grasp the profound mysteries that govern the fundamental aspects of the universe.\n",
    "danish\tdan\tDen danske hygge kultur skaber en atmosfÃ¦re af varme og samhÃ¸righed, der omfavner livets enkle glÃ¦der.\n",
    "finnish\tfin\tSuomen lumiset maisemat tarjoavat unohtumattoman nÃ¤kymÃ¤n pohjoisen luonnon kauneudesta.\n",
    "swedish\tswe\tSverige Ã¤r kÃ¤nt fÃ¶r sin designinnovation och det sÃ¤tt pÃ¥ vilket den integreras i vardagen, vilket skapar en harmonisk livsstil.\n",
    "spanish\tspa\tLa arquitectura gÃ³tica de la catedral de Barcelona es un testimonio impresionante de la destreza artÃ­stica y la devociÃ³n religiosa.\n",
    "german\tger\tDie deutsche Philosophie hat einen tiefgreifenden Einfluss auf das Denken und die intellektuelle Tradition weltweit ausgeÃ¼bt.\n",
    "italian\tita\tL'arte culinaria italiana Ã¨ un'esperienza sensoriale che celebra l'amore per gli ingredienti freschi e la convivialitÃ .\n",
    "french\tfre\tL'effervescence culturelle de Paris, avec ses musÃ©es, ses thÃ©Ã¢tres et ses cafÃ©s, fait de la ville une destination artistique incontournable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [row.split('\\t') for row in  sents.split('\\n') if row != '']\n",
    "sents_df = pd.DataFrame(sents, columns=['language', 'code', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greek: \"Î— ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Ï„Î·Ï‚ Î±Î½Î¸ÏÏÏ€Î¹Î½Î·Ï‚ Ï†ÏÏƒÎ·Ï‚ ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î±Ï„Î­Î»ÎµÎ¹Ï‰Ï„Î· Ï€ÎµÏÎ¹Ï€Î­Ï„ÎµÎ¹Î± Ï€Î¿Ï… Î¼Î±Ï‚ ÎºÎ±Î¸Î¿Î´Î·Î³ÎµÎ¯ ÏƒÎµ Î½Î­ÎµÏ‚ ÎµÎ½Î½Î¿Î¹Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î­Ï‚.\"\n",
      "['Î—', 'ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ·', 'Ï„Î·Ï‚', 'Î±Î½Î¸ÏÏÏ€Î¹Î½Î·Ï‚', 'Ï†ÏÏƒÎ·Ï‚', 'ÎµÎ¯Î½Î±Î¹', 'Î¼Î¹Î±', 'Î±Ï„Î­Î»ÎµÎ¹Ï‰Ï„Î·', 'Ï€ÎµÏÎ¹Ï€Î­Ï„ÎµÎ¹Î±', 'Ï€Î¿Ï…', 'Î¼Î±Ï‚', 'ÎºÎ±Î¸Î¿Î´Î·Î³ÎµÎ¯', 'ÏƒÎµ', 'Î½Î­ÎµÏ‚', 'ÎµÎ½Î½Î¿Î¹Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚', 'Î´Î¹Î±Î´ÏÎ¿Î¼Î­Ï‚', '.']\n",
      "\n",
      "estonian: \"Eesti rannikul jalutades vÃµib tunnetada mere lÃµpmatust ja ajalooliste jutustuste rikkust.\"\n",
      "['Eesti', 'rannikul', 'jalutades', 'vÃµib', 'tunnetada', 'mere', 'lÃµpmatust', 'ja', 'ajalooliste', 'jutustuste', 'rikkust', '.']\n",
      "\n",
      "turkish: \"Anadolu'nun mistik atmosferi, tarih ve kÃ¼ltÃ¼rÃ¼n harmanlandÄ±ÄŸÄ± bir yerdir.\"\n",
      "[\"Anadolu'nun\", 'mistik', 'atmosferi', ',', 'tarih', 've', 'kÃ¼ltÃ¼rÃ¼n', 'harmanlandÄ±ÄŸÄ±', 'bir', 'yerdir', '.']\n",
      "\n",
      "polish: \"CiekawoÅ›Ä‡ i odkrywanie nowych koncepcji stanowiÄ… fundament naszej ludzkiej egzystencji.\"\n",
      "['CiekawoÅ›Ä‡', 'i', 'odkrywanie', 'nowych', 'koncepcji', 'stanowiÄ…', 'fundament', 'naszej', 'ludzkiej', 'egzystencji', '.']\n",
      "\n",
      "russian: \"Ğ ÑƒÑÑĞºĞ°Ñ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´ Ğ½Ğ°Ğ¼Ğ¸ Ğ±Ğ¾Ğ³Ğ°Ñ‚ÑÑ‚Ğ²Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ¸ Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ½Ğ°Ñ Ğ² Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ Ğ´ÑƒÑˆĞ¸.\"\n",
      "['Ğ ÑƒÑÑĞºĞ°Ñ', 'Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°', 'Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚', 'Ğ¿ĞµÑ€ĞµĞ´', 'Ğ½Ğ°Ğ¼Ğ¸', 'Ğ±Ğ¾Ğ³Ğ°Ñ‚ÑÑ‚Ğ²Ğ¾', 'Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾', 'Ğ¾Ğ¿Ñ‹Ñ‚Ğ°', 'Ğ¸', 'Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚', 'Ğ½Ğ°Ñ', 'Ğ²', 'Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹', 'Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹', 'Ğ´ÑƒÑˆĞ¸', '.']\n",
      "\n",
      "czech: \"ÄŒeskÃ¡ krajina oplÃ½vÃ¡ malebnÃ½mi zÃ¡koutÃ­mi a historickÃ½mi pamÃ¡tkami, kterÃ© vyprÃ¡vÄ›jÃ­ pÅ™Ã­bÄ›hy minulosti.\"\n",
      "['ÄŒeskÃ¡', 'krajina', 'oplÃ½vÃ¡', 'malebnÃ½mi', 'zÃ¡koutÃ­mi', 'a', 'historickÃ½mi', 'pamÃ¡tkami', ',', 'kterÃ©', 'vyprÃ¡vÄ›jÃ­', 'pÅ™Ã­bÄ›hy', 'minulosti', '.']\n",
      "\n",
      "portuguese: \"A diversidade cultural do Brasil reflete-se na fusÃ£o de influÃªncias indÃ­genas, africanas e europeias, criando uma rica tapeÃ§aria de tradiÃ§Ãµes.\"\n",
      "['A', 'diversidade', 'cultural', 'do', 'Brasil', 'reflete-se', 'na', 'fusÃ£o', 'de', 'influÃªncias', 'indÃ­genas', ',', 'africanas', 'e', 'europeias', ',', 'criando', 'uma', 'rica', 'tapeÃ§aria', 'de', 'tradiÃ§Ãµes', '.']\n",
      "\n",
      "dutch: \"De grachten van Amsterdam getuigen van een rijke geschiedenis en vormen een intrigerend netwerk dat de stad doorkruist.\"\n",
      "['De', 'grachten', 'van', 'Amsterdam', 'getuigen', 'van', 'een', 'rijke', 'geschiedenis', 'en', 'vormen', 'een', 'intrigerend', 'netwerk', 'dat', 'de', 'stad', 'doorkruist', '.']\n",
      "\n",
      "norwegian: \"Norges majestetiske fjorder og bortgjemte fjelltopper lokker eventyrlystne reisende til Ã¥ utforske naturens underverker.\"\n",
      "['Norges', 'majestetiske', 'fjorder', 'og', 'bortgjemte', 'fjelltopper', 'lokker', 'eventyrlystne', 'reisende', 'til', 'Ã¥', 'utforske', 'naturens', 'underverker', '.']\n",
      "\n",
      "malayalam: \"à´•àµ‡à´°à´³à´¤àµà´¤à´¿à´¨àµà´±àµ† à´¸àµ—à´¨àµà´¦à´°àµà´¯à´‚ à´ªàµà´°à´•à´Ÿà´®à´¾à´•àµà´•àµà´¨àµà´¨ à´…à´•àµà´•à´¾à´¦à´®à´¿à´• à´ªà´°à´¿à´¸àµà´¥à´¿à´¤à´¿à´•àµ¾ à´¹à´¿à´®à´¾à´²à´¯à´¤àµà´¤à´¿à´¨àµà´±àµ† à´¸à´¨àµà´¦àµ¼à´¶à´¨à´¤àµà´¤à´¿à´¨àµ à´•àµ‡à´¨àµà´¦àµà´°àµ€à´•à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ.\"\n",
      "['à´•àµ‡à´°à´³à´¤àµà´¤à´¿à´¨àµà´±àµ†', 'à´¸àµ—à´¨àµà´¦à´°àµà´¯à´‚', 'à´ªàµà´°à´•à´Ÿà´®à´¾à´•àµà´•àµà´¨àµà´¨', 'à´…à´•àµà´•à´¾à´¦à´®à´¿à´•', 'à´ªà´°à´¿à´¸àµà´¥à´¿à´¤à´¿à´•àµ¾', 'à´¹à´¿à´®à´¾à´²à´¯à´¤àµà´¤à´¿à´¨àµà´±àµ†', 'à´¸à´¨àµà´¦àµ¼à´¶à´¨à´¤àµà´¤à´¿à´¨àµ', 'à´•àµ‡à´¨àµà´¦àµà´°àµ€à´•à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ', '.']\n",
      "\n",
      "slovene: \"Slovenski jezik je bogat s svojimi idiomatskimi izrazi, ki odraÅ¾ajo duhovito naravo in globoko Äustvenost.\"\n",
      "['Slovenski', 'jezik', 'je', 'bogat', 's', 'svojimi', 'idiomatskimi', 'izrazi', ',', 'ki', 'odraÅ¾ajo', 'duhovito', 'naravo', 'in', 'globoko', 'Äustvenost', '.']\n",
      "\n",
      "english: \"Delving into the intricacies of quantum mechanics allows us to grasp the profound mysteries that govern the fundamental aspects of the universe.\"\n",
      "['Delving', 'into', 'the', 'intricacies', 'of', 'quantum', 'mechanics', 'allows', 'us', 'to', 'grasp', 'the', 'profound', 'mysteries', 'that', 'govern', 'the', 'fundamental', 'aspects', 'of', 'the', 'universe', '.']\n",
      "\n",
      "danish: \"Den danske hygge kultur skaber en atmosfÃ¦re af varme og samhÃ¸righed, der omfavner livets enkle glÃ¦der.\"\n",
      "['Den', 'danske', 'hygge', 'kultur', 'skaber', 'en', 'atmosfÃ¦re', 'af', 'varme', 'og', 'samhÃ¸righed', ',', 'der', 'omfavner', 'livets', 'enkle', 'glÃ¦der', '.']\n",
      "\n",
      "finnish: \"Suomen lumiset maisemat tarjoavat unohtumattoman nÃ¤kymÃ¤n pohjoisen luonnon kauneudesta.\"\n",
      "['Suomen', 'lumiset', 'maisemat', 'tarjoavat', 'unohtumattoman', 'nÃ¤kymÃ¤n', 'pohjoisen', 'luonnon', 'kauneudesta', '.']\n",
      "\n",
      "swedish: \"Sverige Ã¤r kÃ¤nt fÃ¶r sin designinnovation och det sÃ¤tt pÃ¥ vilket den integreras i vardagen, vilket skapar en harmonisk livsstil.\"\n",
      "['Sverige', 'Ã¤r', 'kÃ¤nt', 'fÃ¶r', 'sin', 'designinnovation', 'och', 'det', 'sÃ¤tt', 'pÃ¥', 'vilket', 'den', 'integreras', 'i', 'vardagen', ',', 'vilket', 'skapar', 'en', 'harmonisk', 'livsstil', '.']\n",
      "\n",
      "spanish: \"La arquitectura gÃ³tica de la catedral de Barcelona es un testimonio impresionante de la destreza artÃ­stica y la devociÃ³n religiosa.\"\n",
      "['La', 'arquitectura', 'gÃ³tica', 'de', 'la', 'catedral', 'de', 'Barcelona', 'es', 'un', 'testimonio', 'impresionante', 'de', 'la', 'destreza', 'artÃ­stica', 'y', 'la', 'devociÃ³n', 'religiosa', '.']\n",
      "\n",
      "german: \"Die deutsche Philosophie hat einen tiefgreifenden Einfluss auf das Denken und die intellektuelle Tradition weltweit ausgeÃ¼bt.\"\n",
      "['Die', 'deutsche', 'Philosophie', 'hat', 'einen', 'tiefgreifenden', 'Einfluss', 'auf', 'das', 'Denken', 'und', 'die', 'intellektuelle', 'Tradition', 'weltweit', 'ausgeÃ¼bt', '.']\n",
      "\n",
      "italian: \"L'arte culinaria italiana Ã¨ un'esperienza sensoriale che celebra l'amore per gli ingredienti freschi e la convivialitÃ .\"\n",
      "[\"L'arte\", 'culinaria', 'italiana', 'Ã¨', \"un'esperienza\", 'sensoriale', 'che', 'celebra', \"l'amore\", 'per', 'gli', 'ingredienti', 'freschi', 'e', 'la', 'convivialitÃ ', '.']\n",
      "\n",
      "french: \"L'effervescence culturelle de Paris, avec ses musÃ©es, ses thÃ©Ã¢tres et ses cafÃ©s, fait de la ville une destination artistique incontournable.\"\n",
      "[\"L'effervescence\", 'culturelle', 'de', 'Paris', ',', 'avec', 'ses', 'musÃ©es', ',', 'ses', 'thÃ©Ã¢tres', 'et', 'ses', 'cafÃ©s', ',', 'fait', 'de', 'la', 'ville', 'une', 'destination', 'artistique', 'incontournable', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create word tokenizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for i, d in sents_df.iterrows():\n",
    "    print(f'{d.language}: \"{d.text}\"')\n",
    "    print(word_tokenize(d.text, language=d.language))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `stanza`\n",
    "\n",
    "supported languages are listed here: https://stanfordnlp.github.io/stanza/performance.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sl',\n",
       " 'sk',\n",
       " 'ur',\n",
       " 'zh-hans',\n",
       " 'kmr',\n",
       " 'zh-hant',\n",
       " 'ug',\n",
       " 'pl',\n",
       " 'bxr',\n",
       " 'vi',\n",
       " 'fro',\n",
       " 'sv',\n",
       " 'ga',\n",
       " 'he',\n",
       " 'mt',\n",
       " 'qaf',\n",
       " 'hy',\n",
       " 'nn',\n",
       " 'be',\n",
       " 'da',\n",
       " 'mr',\n",
       " 'kk',\n",
       " 'ky',\n",
       " 'grc',\n",
       " 'ja',\n",
       " 'cu',\n",
       " 'el',\n",
       " 'lv',\n",
       " 'it',\n",
       " 'ca',\n",
       " 'is',\n",
       " 'cs',\n",
       " 'te',\n",
       " 'ru',\n",
       " 'got',\n",
       " 'resources.json',\n",
       " 'ro',\n",
       " 'hsb',\n",
       " 'hyw',\n",
       " 'sa',\n",
       " 'pt',\n",
       " 'qpm',\n",
       " 'uk',\n",
       " 'sr',\n",
       " 'pcm',\n",
       " 'lij',\n",
       " 'ar',\n",
       " 'gl',\n",
       " 'gv',\n",
       " 'hr',\n",
       " 'hu',\n",
       " 'nl',\n",
       " 'bg',\n",
       " 'myv',\n",
       " 'af',\n",
       " 'nb',\n",
       " 'hi',\n",
       " 'de',\n",
       " 'sme',\n",
       " 'gd',\n",
       " 'ko',\n",
       " 'fi',\n",
       " 'orv',\n",
       " 'id',\n",
       " 'fr',\n",
       " 'es',\n",
       " 'et',\n",
       " 'en',\n",
       " 'fa',\n",
       " 'lt',\n",
       " 'fo',\n",
       " 'cy',\n",
       " 'eu',\n",
       " 'hbo',\n",
       " 'la',\n",
       " 'qtd',\n",
       " 'ta',\n",
       " 'lzh',\n",
       " 'tr',\n",
       " 'cop',\n",
       " 'wo']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list tokenizer resources for stanza\n",
    "import os\n",
    "os.listdir(os.path.join(os.path.expanduser('~'), 'stanza_resources'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ancient Greek</td>\n",
       "      <td>grc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ancient Hebrew</td>\n",
       "      <td>hbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenian</td>\n",
       "      <td>hy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Uyghur</td>\n",
       "      <td>ug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Western Armenian</td>\n",
       "      <td>hyw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Wolof</td>\n",
       "      <td>wo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            language code\n",
       "0          Afrikaans   af\n",
       "1      Ancient Greek  grc\n",
       "2     Ancient Hebrew  hbo\n",
       "3             Arabic   ar\n",
       "4           Armenian   hy\n",
       "..               ...  ...\n",
       "75            Uyghur   ug\n",
       "76        Vietnamese   vi\n",
       "77             Welsh   cy\n",
       "78  Western Armenian  hyw\n",
       "79             Wolof   wo\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = 'https://github.com/fabiennelind/Going-Cross-Lingual_Course/blob/main/resources/stanza_tokenization_language_support.tsv'\n",
    "pd.read_csv(fp, sep='\\t'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = \"\"\"\n",
    "Afrikaans\taf\tEk hou van om in die natuur te wandel.\n",
    "Ancient Greek\tgrc\tÎ§Î±Î¯ÏÎµÏ„Îµ, á½¦ ÎºÏŒÏƒÎ¼Îµ!\n",
    "Ancient Hebrew\thbo\t×©Ö¸××œ×•Ö¹× ×œÖ¸×›Ö¶×\n",
    "Arabic\tar\tØ§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡\n",
    "Armenian\thy\tÔ²Õ¡Ö€Õ¥Ö‚, Õ¡Õ·Õ­Õ¡Ö€Õ°!\n",
    "Basque\teu\tKaixo mundua!\n",
    "Belarusian\tbe\tĞŸÑ€Ñ‹Ğ²Ñ–Ñ‚Ğ°Ğ½Ğ½Ğµ, ÑĞ²ĞµÑ‚!\n",
    "Bulgarian\tbg\tĞ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹Ñ‚Ğµ, ÑĞ²ÑÑ‚!\n",
    "Buryat\tbxr\tĞ¡Ğ°Ğ¹Ğ½ Ğ±Ğ°Ğ¹Ğ½Ğ° ÑƒÑƒ?\n",
    "Catalan\tca\tHola, mÃ³n!\n",
    "Chinese (Simplified)\tzh-hans\tä½ å¥½ï¼Œä¸–ç•Œï¼\n",
    "Chinese (Traditional)\tzh-hant\tä½ å¥½ï¼Œä¸–ç•Œï¼\n",
    "Classical Chinese\tlzh\tä¸–ç•Œå®‰å¥½\n",
    "Coptic\tcop\tÏ¨â²Ÿâ²©â²§â²â²§â²â²£â²“â²Ÿâ²›â²â²§â²“ Ï­â²Ÿâ²Ÿâ²©â²§ â²›Ì€â²§â²‰â²›â²â²©â²§â²â²£\n",
    "Croatian\thr\tPozdrav, svijete!\n",
    "Czech\tcs\tAhoj, svÄ›te!\n",
    "Danish\tda\tHej verden!\n",
    "Dutch\tnl\tHallo, wereld!\n",
    "English\ten\tHello, world!\n",
    "Erzya\tmyv\tĞ¢ĞµĞ²ĞµĞ¼Ğµ Ğ²Ğ°Ñ€ÑĞ½Ñ‚Ğ¸ÑÑŒ!\n",
    "Estonian\tet\tTere, maailm!\n",
    "Faroese\tfo\tHallÃ³, heimur!\n",
    "Finnish\tfi\tHei, maailma!\n",
    "French\tfr\tBonjour, le monde !\n",
    "Galician\tgl\tOla, mundo!\n",
    "German\tde\tHallo, Welt!\n",
    "Gothic\tgot\tğŒ·ğŒ°ğŒ½ğƒ, ğŒ°ğŒ·ğ„ğŒ¹ğŒ¿ğƒ!\n",
    "Greek\tel\tÎ“ÎµÎ¹Î± ÏƒÎ±Ï‚, ÎºÏŒÏƒÎ¼Îµ!\n",
    "Hebrew\the\t×©×œ×•× ×¢×•×œ×\n",
    "Hindi\thi\tà¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤¦à¥à¤¨à¤¿à¤¯à¤¾!\n",
    "Hungarian\thu\tHellÃ³, vilÃ¡g!\n",
    "Icelandic\tis\tHallÃ³, heimur!\n",
    "Indonesian\tid\tHalo, dunia!\n",
    "Irish\tga\tDia dhuit, domhan!\n",
    "Italian\tit\tCiao, mondo!\n",
    "Japanese\tja\tã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼\n",
    "Kazakh\tkk\tĞ¡Ó™Ğ»ĞµĞ¼ĞµÑ‚ÑÑ–Ğ·Ğ´ĞµÑ€Ğ³Ğµ, Ó©Ñ‚ĞºĞµĞ½!\n",
    "Korean\tko\tì•ˆë…•í•˜ì„¸ìš”, ì„¸ê³„!\n",
    "Kurmanji\tkmr\tSilav, cÃ®han!\n",
    "Kyrgyz\tky\tĞ¡Ğ°Ğ»Ğ°Ğ¼Ğ°Ñ‚ÑÑ‹Ğ·Ğ´Ğ°Ñ€Ğ³Ğ°, Ğ´Ò¯Ğ¹Ğ½Ó©!\n",
    "Latin\tla\tSalve, mundus!\n",
    "Latvian\tlv\tSveiki, pasaule!\n",
    "Ligurian\tlij\tCiao, mondo!\n",
    "Lithuanian\tlt\tLabas, pasauli!\n",
    "Maghrebi Arabic French\tqaf\tØ§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…ØŒ Ø¹Ø§Ù„Ù…!\n",
    "Maltese\tmt\tBongu, dinja!\n",
    "Manx\tgv\tLaa rieau, yn cheer!\n",
    "Marathi\tmr\tà¤¹à¥…à¤²à¥‹, à¤œà¤—!\n",
    "Naija\tpcm\tHow far, world!\n",
    "North Sami\tsme\tÄŒÃ¡zeheaddji, oktavuohta!\n",
    "Norwegian\tnb\tHei, verden!\n",
    "Norwegian Nynorsk\tnn\tHei, verda!\n",
    "Old Church Slavonic\tcu\tĞ—Ğ´Ñ€aĞ²Ñ£Ğ¸Ì†, ÑĞ²Ñ£Ñ‚Ñ£!\n",
    "Old East Slavic\torv\tĞ—Ğ´Ñ€aĞ²Ñ£Ğ¸Ì†, Ğ¼Ğ¸Ñ€ÑŠ!\n",
    "Old French\tfro\tSalut, monde!\n",
    "Persian\tfa\tØ³Ù„Ø§Ù…ØŒ Ø¬Ù‡Ø§Ù†!\n",
    "Polish\tpl\tWitaj, Å›wiecie!\n",
    "Pomak\tqpm\tĞ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹, ÑĞ²ÑÑ‚!\n",
    "Portuguese\tpt\tOlÃ¡, mundo!\n",
    "Romanian\tro\tSalut, lume!\n",
    "Russian\tru\tĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ğ¼Ğ¸Ñ€!\n",
    "Sanskrit\tsa\tà¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤²à¥‹à¤•!\n",
    "Scottish Gaelic\tgd\tHÃ lo, saoghal!\n",
    "Serbian\tsr\tĞ—Ğ´Ñ€Ğ°Ğ²Ğ¾, ÑĞ²ĞµÑ‚Ğµ!\n",
    "Slovak\tsk\tAhoj, svet!\n",
    "Slovenian\tsl\tZdravo, svet!\n",
    "Spanish\tes\tÂ¡Hola, mundo!\n",
    "Swedish\tsv\tHej, vÃ¤rlden!\n",
    "Tamil\tta\tà®µà®£à®•à¯à®•à®®à¯, à®‰à®²à®•à¯‡!\n",
    "Telugu\tte\tà°¹à°²à±‹, à°ªà±à°°à°ªà°‚à°šà°‚!\n",
    "Turkish\ttr\tMerhaba, dÃ¼nya!\n",
    "Turkish German\tqtd\tMerhaba, dÃ¼nya!\n",
    "Ukrainian\tuk\tĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚, ÑĞ²Ñ–Ñ‚!\n",
    "Upper Sorbian\thsb\tHellos, swÄ›t!\n",
    "Urdu\tur\tÛÛŒÙ„ÙˆØŒ Ø¯Ù†ÛŒØ§!\n",
    "Uyghur\tug\tÚ¾Û•Ù„Û•Ù„Û‡ØŒ Ø¯Û‡Ù†ÙŠØ§!\n",
    "Vietnamese\tvi\tChÃ o báº¡n, tháº¿ giá»›i!\n",
    "Welsh\tcy\tHelo, byd!\n",
    "Western Armenian\thyw\tÕˆÕ²Õ»Õ¸Ö‚ÕµÕ¶, Õ¡Õ·Õ­Õ¡Ö€Õ°!\n",
    "Wolof\two\tNopp naa ngi ci biir!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [row.split('\\t') for row in  sents.split('\\n') if row != '']\n",
    "sents_df = pd.DataFrame(sents, columns=['language', 'code', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afrikaans: \"Ek hou van om in die natuur te wandel.\"\n",
      "['Ek', 'hou', 'van', 'om', 'in', 'die', 'natuur', 'te', 'wandel', '.']\n",
      "\n",
      "Ancient Greek: \"Î§Î±Î¯ÏÎµÏ„Îµ, á½¦ ÎºÏŒÏƒÎ¼Îµ!\"\n",
      "['Î§Î±Î¯ÏÎµÏ„Îµ,', 'á½¦', 'ÎºÏŒÏƒÎ¼Îµ!']\n",
      "\n",
      "Ancient Hebrew: \"×©Ö¸××œ×•Ö¹× ×œÖ¸×›Ö¶×\"\n",
      "['×©Ö¸××œ×•Ö¹×', '×œÖ¸×›Ö¶×']\n",
      "\n",
      "Arabic: \"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡\"\n",
      "['Ø§Ù„Ø³Ù„Ø§Ù…', 'Ø¹Ù„ÙŠÙƒÙ…', 'ÙˆØ±Ø­Ù…Ø©', 'Ø§Ù„Ù„Ù‡', 'ÙˆØ¨Ø±ÙƒØ§ØªÙ‡']\n",
      "\n",
      "Armenian: \"Ô²Õ¡Ö€Õ¥Ö‚, Õ¡Õ·Õ­Õ¡Ö€Õ°!\"\n",
      "['Ô²Õ¡Ö€Õ¥Ö‚', ',', 'Õ¡Õ·Õ­Õ¡Ö€Õ°!']\n",
      "\n",
      "Basque: \"Kaixo mundua!\"\n",
      "['Kaixo', 'mundua', '!']\n",
      "\n",
      "Belarusian: \"ĞŸÑ€Ñ‹Ğ²Ñ–Ñ‚Ğ°Ğ½Ğ½Ğµ, ÑĞ²ĞµÑ‚!\"\n",
      "['ĞŸÑ€Ñ‹Ğ²Ñ–Ñ‚Ğ°Ğ½Ğ½Ğµ', ',', 'ÑĞ²ĞµÑ‚', '!']\n",
      "\n",
      "Bulgarian: \"Ğ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹Ñ‚Ğµ, ÑĞ²ÑÑ‚!\"\n",
      "['Ğ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹Ñ‚Ğµ', ',', 'ÑĞ²ÑÑ‚', '!']\n",
      "\n",
      "Buryat: \"Ğ¡Ğ°Ğ¹Ğ½ Ğ±Ğ°Ğ¹Ğ½Ğ° ÑƒÑƒ?\"\n",
      "['Ğ¡Ğ°Ğ¹Ğ½', 'Ğ±Ğ°Ğ¹Ğ½Ğ°', 'ÑƒÑƒ', '?']\n",
      "\n",
      "Catalan: \"Hola, mÃ³n!\"\n",
      "['Hola', ',', 'mÃ³n', '!']\n",
      "\n",
      "Chinese (Simplified): \"ä½ å¥½ï¼Œä¸–ç•Œï¼\"\n",
      "['ä½ å¥½', 'ï¼Œ', 'ä¸–ç•Œ', 'ï¼']\n",
      "\n",
      "Chinese (Traditional): \"ä½ å¥½ï¼Œä¸–ç•Œï¼\"\n",
      "['ä½ ', 'å¥½', 'ï¼Œ', 'ä¸–ç•Œ', 'ï¼']\n",
      "\n",
      "Classical Chinese: \"ä¸–ç•Œå®‰å¥½\"\n",
      "['ä¸–', 'ç•Œ', 'å®‰', 'å¥½']\n",
      "\n",
      "Coptic: \"Ï¨â²Ÿâ²©â²§â²â²§â²â²£â²“â²Ÿâ²›â²â²§â²“ Ï­â²Ÿâ²Ÿâ²©â²§ â²›Ì€â²§â²‰â²›â²â²©â²§â²â²£\"\n",
      "['Ï¨â²Ÿâ²©â²§â²â²§â²â²£â²“â²Ÿâ²›â²â²§â²“', 'Ï­â²Ÿâ²Ÿâ²©â²§', 'â²›Ì€â²§â²‰â²›â²â²©â²§â²â²£']\n",
      "\n",
      "Croatian: \"Pozdrav, svijete!\"\n",
      "['Pozdrav', ',', 'svijete', '!']\n",
      "\n",
      "Czech: \"Ahoj, svÄ›te!\"\n",
      "['Ahoj', ',', 'svÄ›te', '!']\n",
      "\n",
      "Danish: \"Hej verden!\"\n",
      "['Hej', 'verden', '!']\n",
      "\n",
      "Dutch: \"Hallo, wereld!\"\n",
      "['Hallo', ',', 'wereld', '!']\n",
      "\n",
      "English: \"Hello, world!\"\n",
      "['Hello', ',', 'world', '!']\n",
      "\n",
      "Erzya: \"Ğ¢ĞµĞ²ĞµĞ¼Ğµ Ğ²Ğ°Ñ€ÑĞ½Ñ‚Ğ¸ÑÑŒ!\"\n",
      "['Ğ¢ĞµĞ²ĞµĞ¼Ğµ', 'Ğ²Ğ°Ñ€ÑĞ½Ñ‚Ğ¸ÑÑŒ', '!']\n",
      "\n",
      "Estonian: \"Tere, maailm!\"\n",
      "['Tere', ',', 'maailm', '!']\n",
      "\n",
      "Faroese: \"HallÃ³, heimur!\"\n",
      "['HallÃ³', ',', 'heimur', '!']\n",
      "\n",
      "Finnish: \"Hei, maailma!\"\n",
      "['Hei', ',', 'maailma', '!']\n",
      "\n",
      "French: \"Bonjour, le monde !\"\n",
      "['Bonjour', ',', 'le', 'monde', '!']\n",
      "\n",
      "Galician: \"Ola, mundo!\"\n",
      "['Ola', ',', 'mundo', '!']\n",
      "\n",
      "German: \"Hallo, Welt!\"\n",
      "['Hallo', ',', 'Welt', '!']\n",
      "\n",
      "Gothic: \"ğŒ·ğŒ°ğŒ½ğƒ, ğŒ°ğŒ·ğ„ğŒ¹ğŒ¿ğƒ!\"\n",
      "['ğŒ·ğŒ°ğŒ½ğƒ,', 'ğŒ°ğŒ·ğ„ğŒ¹ğŒ¿ğƒ', '!']\n",
      "\n",
      "Greek: \"Î“ÎµÎ¹Î± ÏƒÎ±Ï‚, ÎºÏŒÏƒÎ¼Îµ!\"\n",
      "['Î“ÎµÎ¹Î±', 'ÏƒÎ±Ï‚', ',', 'ÎºÏŒÏƒÎ¼Îµ', '!']\n",
      "\n",
      "Hebrew: \"×©×œ×•× ×¢×•×œ×\"\n",
      "['×©×œ×•×', '×¢×•×œ×']\n",
      "\n",
      "Hindi: \"à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤¦à¥à¤¨à¤¿à¤¯à¤¾!\"\n",
      "['à¤¨à¤®à¤¸à¥à¤¤à¥‡', ',', 'à¤¦à¥à¤¨à¤¿à¤¯à¤¾', '!']\n",
      "\n",
      "Hungarian: \"HellÃ³, vilÃ¡g!\"\n",
      "['HellÃ³', ',', 'vilÃ¡g', '!']\n",
      "\n",
      "Icelandic: \"HallÃ³, heimur!\"\n",
      "['HallÃ³', ',', 'heimur', '!']\n",
      "\n",
      "Indonesian: \"Halo, dunia!\"\n",
      "['Halo', ',', 'dunia', '!']\n",
      "\n",
      "Irish: \"Dia dhuit, domhan!\"\n",
      "['Dia', 'dhuit', ',', 'domhan', '!']\n",
      "\n",
      "Italian: \"Ciao, mondo!\"\n",
      "['Ciao', ',', 'mondo', '!']\n",
      "\n",
      "Japanese: \"ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼\"\n",
      "['ã“ã‚“', 'ã«ã¡', 'ã¯', 'ã€', 'ä¸–ç•Œ', 'ï¼']\n",
      "\n",
      "Kazakh: \"Ğ¡Ó™Ğ»ĞµĞ¼ĞµÑ‚ÑÑ–Ğ·Ğ´ĞµÑ€Ğ³Ğµ, Ó©Ñ‚ĞºĞµĞ½!\"\n",
      "['Ğ¡Ó™Ğ»ĞµĞ¼ĞµÑ‚ÑÑ–Ğ·Ğ´ĞµÑ€Ğ³Ğµ', ',', 'Ó©Ñ‚ĞºĞµĞ½', '!']\n",
      "\n",
      "Korean: \"ì•ˆë…•í•˜ì„¸ìš”, ì„¸ê³„!\"\n",
      "['ì•ˆë…•í•˜ì„¸ìš”', ',', 'ì„¸ê³„', '!']\n",
      "\n",
      "Kurmanji: \"Silav, cÃ®han!\"\n",
      "['Silav', ',', 'cÃ®han', '!']\n",
      "\n",
      "Kyrgyz: \"Ğ¡Ğ°Ğ»Ğ°Ğ¼Ğ°Ñ‚ÑÑ‹Ğ·Ğ´Ğ°Ñ€Ğ³Ğ°, Ğ´Ò¯Ğ¹Ğ½Ó©!\"\n",
      "['Ğ¡Ğ°Ğ»Ğ°Ğ¼Ğ°Ñ‚ÑÑ‹Ğ·Ğ´Ğ°Ñ€Ğ³Ğ°', ',', 'Ğ´Ò¯Ğ¹Ğ½Ó©', '!']\n",
      "\n",
      "Latin: \"Salve, mundus!\"\n",
      "['Salve', ',', 'mundus', '!']\n",
      "\n",
      "Latvian: \"Sveiki, pasaule!\"\n",
      "['Sveiki', ',', 'pasaule', '!']\n",
      "\n",
      "Ligurian: \"Ciao, mondo!\"\n",
      "['Ciao', ',', 'mondo', '!']\n",
      "\n",
      "Lithuanian: \"Labas, pasauli!\"\n",
      "['Labas', ',', 'pasauli', '!']\n",
      "\n",
      "Maghrebi Arabic French: \"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…ØŒ Ø¹Ø§Ù„Ù…!\"\n",
      "['Ø§Ù„Ø³Ù„Ø§Ù…', 'Ø¹Ù„ÙŠÙƒÙ…ØŒ', 'Ø¹Ø§Ù„Ù…!']\n",
      "\n",
      "Maltese: \"Bongu, dinja!\"\n",
      "['Bongu', ',', 'dinja', '!']\n",
      "\n",
      "Manx: \"Laa rieau, yn cheer!\"\n",
      "['Laa', 'rieau', ',', 'yn', 'cheer', '!']\n",
      "\n",
      "Marathi: \"à¤¹à¥…à¤²à¥‹, à¤œà¤—!\"\n",
      "['à¤¹à¥…à¤²à¥‹', ',', 'à¤œà¤—', '!']\n",
      "\n",
      "Naija: \"How far, world!\"\n",
      "['How', 'far,', 'world!']\n",
      "\n",
      "North Sami: \"ÄŒÃ¡zeheaddji, oktavuohta!\"\n",
      "['ÄŒÃ¡zeheaddji', ',', 'oktavuohta', '!']\n",
      "\n",
      "Norwegian: \"Hei, verden!\"\n",
      "['Hei', ',', 'verden', '!']\n",
      "\n",
      "Norwegian Nynorsk: \"Hei, verda!\"\n",
      "['Hei', ',', 'verda', '!']\n",
      "\n",
      "Old Church Slavonic: \"Ğ—Ğ´Ñ€aĞ²Ñ£Ğ¸Ì†, ÑĞ²Ñ£Ñ‚Ñ£!\"\n",
      "['Ğ—Ğ´Ñ€aĞ²Ñ£Ğ¸Ì†,', 'ÑĞ²Ñ£Ñ‚Ñ£!']\n",
      "\n",
      "Old East Slavic: \"Ğ—Ğ´Ñ€aĞ²Ñ£Ğ¸Ì†, Ğ¼Ğ¸Ñ€ÑŠ!\"\n",
      "['Ğ—Ğ´Ñ€aĞ²Ñ£Ğ¸Ì†,', 'Ğ¼Ğ¸Ñ€ÑŠ', '!']\n",
      "\n",
      "Old French: \"Salut, monde!\"\n",
      "['Salut', ',', 'monde!']\n",
      "\n",
      "Persian: \"Ø³Ù„Ø§Ù…ØŒ Ø¬Ù‡Ø§Ù†!\"\n",
      "['Ø³Ù„Ø§Ù…', 'ØŒ', 'Ø¬Ù‡Ø§Ù†', '!']\n",
      "\n",
      "Polish: \"Witaj, Å›wiecie!\"\n",
      "['Witaj', ',', 'Å›wiecie', '!']\n",
      "\n",
      "Pomak: \"Ğ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹, ÑĞ²ÑÑ‚!\"\n",
      "['Ğ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹', ',', 'ÑĞ²ÑÑ‚', '!']\n",
      "\n",
      "Portuguese: \"OlÃ¡, mundo!\"\n",
      "['OlÃ¡', ',', 'mundo', '!']\n",
      "\n",
      "Romanian: \"Salut, lume!\"\n",
      "['Salut', ',', 'lume', '!']\n",
      "\n",
      "Russian: \"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ğ¼Ğ¸Ñ€!\"\n",
      "['ĞŸÑ€Ğ¸Ğ²ĞµÑ‚', ',', 'Ğ¼Ğ¸Ñ€', '!']\n",
      "\n",
      "Sanskrit: \"à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤²à¥‹à¤•!\"\n",
      "['à¤¨à¤®à¤¸à¥à¤¤à¥‡,', 'à¤²à¥‹à¤•!']\n",
      "\n",
      "Scottish Gaelic: \"HÃ lo, saoghal!\"\n",
      "['HÃ lo', ',', 'saoghal', '!']\n",
      "\n",
      "Serbian: \"Ğ—Ğ´Ñ€Ğ°Ğ²Ğ¾, ÑĞ²ĞµÑ‚Ğµ!\"\n",
      "['Ğ—Ğ´Ñ€Ğ°Ğ²Ğ¾', ',', 'ÑĞ²ĞµÑ‚Ğµ', '!']\n",
      "\n",
      "Slovak: \"Ahoj, svet!\"\n",
      "['Ahoj', ',', 'svet', '!']\n",
      "\n",
      "Slovenian: \"Zdravo, svet!\"\n",
      "['Zdravo', ',', 'svet', '!']\n",
      "\n",
      "Spanish: \"Â¡Hola, mundo!\"\n",
      "['Â¡', 'Hola', ',', 'mundo', '!']\n",
      "\n",
      "Swedish: \"Hej, vÃ¤rlden!\"\n",
      "['Hej', ',', 'vÃ¤rlden', '!']\n",
      "\n",
      "Tamil: \"à®µà®£à®•à¯à®•à®®à¯, à®‰à®²à®•à¯‡!\"\n",
      "['à®µà®£à®•à¯à®•à®®à¯', ',', 'à®‰à®²à®•à¯‡!']\n",
      "\n",
      "Telugu: \"à°¹à°²à±‹, à°ªà±à°°à°ªà°‚à°šà°‚!\"\n",
      "['à°¹à°²à±‹', ',', 'à°ªà±à°°à°ªà°‚à°šà°‚', '!']\n",
      "\n",
      "Turkish: \"Merhaba, dÃ¼nya!\"\n",
      "['Merhaba', ',', 'dÃ¼nya', '!']\n",
      "\n",
      "Turkish German: \"Merhaba, dÃ¼nya!\"\n",
      "['Merhaba', ',', 'dÃ¼nya', '!']\n",
      "\n",
      "Ukrainian: \"ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚, ÑĞ²Ñ–Ñ‚!\"\n",
      "['ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚', ',', 'ÑĞ²Ñ–Ñ‚', '!']\n",
      "\n",
      "Upper Sorbian: \"Hellos, swÄ›t!\"\n",
      "['Hellos', ',', 'swÄ›t', '!']\n",
      "\n",
      "Urdu: \"ÛÛŒÙ„ÙˆØŒ Ø¯Ù†ÛŒØ§!\"\n",
      "['ÛÛŒÙ„Ùˆ', 'ØŒ', 'Ø¯Ù†ÛŒØ§', '!']\n",
      "\n",
      "Uyghur: \"Ú¾Û•Ù„Û•Ù„Û‡ØŒ Ø¯Û‡Ù†ÙŠØ§!\"\n",
      "['Ú¾Û•Ù„Û•Ù„Û‡', 'ØŒ', 'Ø¯Û‡Ù†ÙŠØ§', '!']\n",
      "\n",
      "Vietnamese: \"ChÃ o báº¡n, tháº¿ giá»›i!\"\n",
      "['ChÃ o', 'báº¡', 'n,', 'tháº¿ giá»›i', '!']\n",
      "\n",
      "Welsh: \"Helo, byd!\"\n",
      "['Helo', ',', 'byd', '!']\n",
      "\n",
      "Western Armenian: \"ÕˆÕ²Õ»Õ¸Ö‚ÕµÕ¶, Õ¡Õ·Õ­Õ¡Ö€Õ°!\"\n",
      "['ÕˆÕ²Õ»Õ¸Ö‚ÕµÕ¶', ',', 'Õ¡Õ·Õ­Õ¡Ö€Õ°', '!']\n",
      "\n",
      "Wolof: \"Nopp naa ngi ci biir!\"\n",
      "['Nopp', 'naa', 'ngi', 'ci', 'biir', '!']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "for i, d in sents_df.iterrows():\n",
    "    print(f'{d.language}: \"{d.text}\"')\n",
    "    doc = stanza.Pipeline(lang=d.code, processors='tokenize', verbose=False)(d.text)\n",
    "    print([tok.text for sent in doc.sentences for tok in sent.tokens])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence tokenization/segmentation/splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return a sentence-tokenized copy of *text*,\n",
      "using NLTK's recommended sentence tokenizer\n",
      "(currently :class:`.PunktSentenceTokenizer`\n",
      "for the specified language).\n",
      "\n",
      ":param text: text to split into sentences\n",
      ":param language: the model name in the Punkt corpus\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniforge3/envs/multilingual/lib/python3.10/site-packages/nltk/tokenize/__init__.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence.', 'This is the second sentence.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sentences = 'This is the first sentence. This is the second sentence.'\n",
    "\n",
    "sent_tokenize(two_sentences, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esta es la primera frase.', 'Esta es la segunda frase.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sentences = 'Esta es la primera frase. Esta es la segunda frase.'\n",
    "\n",
    "sent_tokenize(two_sentences, language='spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence, with a Mr. Smith.',\n",
       " 'This is the second sentence.',\n",
       " 'And now the hon.',\n",
       " 'Gentleman will speak.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_complicated_sentences = 'This is the first sentence, with a Mr. Smith. This is the second sentence. And now the hon. Gentleman will speak.'\n",
    "sent_tokenize(two_complicated_sentences, language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note_:** there is a solution to add custom rules to [prevent such errors](https://stackoverflow.com/a/25375857) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Â¿CuÃ¡ntas veces, en un dÃ­a tÃ­pico, te detienes a reflexionar sobre la complejidad intrÃ­nseca de la existencia humana, con sus interconexiones profundas y su capacidad infinita para la sorpresa y la maravilla?',\n",
       " 'A medida que exploramos las vastas extensiones del conocimiento, Â¿no te parece fascinante cÃ³mo se entrelazan las mÃºltiples disciplinas cientÃ­ficas, desde la fÃ­sica cuÃ¡ntica hasta la biologÃ­a molecular, revelando un universo de posibilidades aÃºn por descubrir?']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_complicated_sentences = (\n",
    "    'Â¿CuÃ¡ntas veces, en un dÃ­a tÃ­pico, te detienes a reflexionar sobre la complejidad intrÃ­nseca de la existencia humana, con sus interconexiones profundas y su capacidad infinita para la sorpresa y la maravilla?'\n",
    "    ' '\n",
    "    'A medida que exploramos las vastas extensiones del conocimiento, Â¿no te parece fascinante cÃ³mo se entrelazan las mÃºltiples disciplinas cientÃ­ficas, desde la fÃ­sica cuÃ¡ntica hasta la biologÃ­a molecular, revelando un universo de posibilidades aÃºn por descubrir?'\n",
    ")\n",
    "sent_tokenize(two_complicated_sentences, language='spanish')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `stanza`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is the first sentence.', 'This is the second sentence.']\n",
      "['This is the first sentence, with a Mr. Smith.', 'This is the second sentence.', 'And now the hon.', 'Gentleman will speak.']\n"
     ]
    }
   ],
   "source": [
    "# english\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize', verbose=False)\n",
    "\n",
    "two_sentences = 'This is the first sentence. This is the second sentence.'\n",
    "doc = nlp(two_sentences)\n",
    "print([sent.text for sent in doc.sentences])\n",
    "\n",
    "two_complicated_sentences = 'This is the first sentence, with a Mr. Smith. This is the second sentence. And now the hon. Gentleman will speak.'\n",
    "doc = nlp(two_complicated_sentences)\n",
    "print([sent.text for sent in doc.sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** There seems to be [a way to handle](https://github.com/stanfordnlp/stanza/issues/1055#issuecomment-1744320976) errors as in the last sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Esta es la primera frase.', 'Esta es la segunda frase.']\n",
      "['Â¿CuÃ¡ntas veces, en un dÃ­a tÃ­pico, te detienes a reflexionar sobre la complejidad intrÃ­nseca de la existencia humana, con sus interconexiones profundas y su capacidad infinita para la sorpresa y la maravilla?', 'A medida que exploramos las vastas extensiones del conocimiento, Â¿no te parece fascinante cÃ³mo se entrelazan las mÃºltiples disciplinas cientÃ­ficas, desde la fÃ­sica cuÃ¡ntica hasta la biologÃ­a molecular, revelando un universo de posibilidades aÃºn por descubrir?']\n"
     ]
    }
   ],
   "source": [
    "# spanish\n",
    "nlp = stanza.Pipeline(lang='es', processors='tokenize', verbose=False)\n",
    "\n",
    "two_sentences = 'Esta es la primera frase. Esta es la segunda frase.'\n",
    "doc = nlp(two_sentences)\n",
    "print([sent.text for sent in doc.sentences])\n",
    "\n",
    "two_complicated_sentences = (\n",
    "    'Â¿CuÃ¡ntas veces, en un dÃ­a tÃ­pico, te detienes a reflexionar sobre la complejidad intrÃ­nseca de la existencia humana, con sus interconexiones profundas y su capacidad infinita para la sorpresa y la maravilla?'\n",
    "    ' '\n",
    "    'A medida que exploramos las vastas extensiones del conocimiento, Â¿no te parece fascinante cÃ³mo se entrelazan las mÃºltiples disciplinas cientÃ­ficas, desde la fÃ­sica cuÃ¡ntica hasta la biologÃ­a molecular, revelando un universo de posibilidades aÃºn por descubrir?'\n",
    "\n",
    ")\n",
    "doc = nlp(two_complicated_sentences)\n",
    "print([sent.text for sent in doc.sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained tokenizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 31414, 232, 6, 127, 766, 16, 24874, 1071, 328, 2]\n",
      "0\t<s>\n",
      "31414\tHello\n",
      "232\t world\n",
      "6\t,\n",
      "127\t my\n",
      "766\t name\n",
      "16\t is\n",
      "24874\t Hau\n",
      "1071\tke\n",
      "328\t!\n",
      "2\t</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Hello world, my name is Hauke!</s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# monolingual\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "encoding = tokenizer('Hello world, my name is Hauke!')\n",
    "print(encoding['input_ids'])\n",
    "for tok in encoding['input_ids']:\n",
    "    print(tok, tokenizer.decode(tok), sep='\\t')\n",
    "tokenizer.decode(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 35378, 8999, 4, 759, 9351, 83, 203755, 13, 38, 2], [0, 54029, 12389, 4, 8172, 15757, 443, 203755, 13, 38, 2]]\n",
      "0\t<s>\n",
      "35378\tHello\n",
      "8999\tworld\n",
      "4\t,\n",
      "759\tmy\n",
      "9351\tname\n",
      "83\tis\n",
      "203755\tHauk\n",
      "13\te\n",
      "38\t!\n",
      "2\t</s>\n",
      "\n",
      "0\t<s>\n",
      "54029\tHallo\n",
      "12389\tWelt\n",
      "4\t,\n",
      "8172\tmein\n",
      "15757\tName\n",
      "443\tist\n",
      "203755\tHauk\n",
      "13\te\n",
      "38\t!\n",
      "2\t</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multilingual\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "\n",
    "encoding = tokenizer(['Hello world, my name is Hauke!', 'Hallo Welt, mein Name ist Hauke!'])\n",
    "print(encoding['input_ids'])\n",
    "for sample in encoding['input_ids']:\n",
    "    for tok in sample:\n",
    "        print(tok, tokenizer.decode(tok), sep='\\t')\n",
    "    print(  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: easyNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynmt import EasyNMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M2M-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_model = EasyNMT('m2m_100_418M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–Î—', 'â–ÎµÎ¾Îµ', 'ÏÎµÏ', 'Î½Î·', 'ÏƒÎ·', 'â–Ï„Î·Ï‚', 'â–Î±Î½Î¸ÏÏ', 'Ï€Î¹', 'Î½Î·Ï‚', 'â–Ï†Ï', 'ÏƒÎ·Ï‚', 'â–ÎµÎ¯Î½Î±Î¹', 'â–Î¼Î¹Î±', 'â–Î±', 'Ï„Î­', 'Î»ÎµÎ¹', 'Ï‰', 'Ï„Î·', 'â–Ï€ÎµÏÎ¹', 'Ï€Î­', 'Ï„', 'ÎµÎ¹Î±', 'â–Ï€Î¿Ï…', 'â–Î¼Î±Ï‚', 'â–ÎºÎ±Î¸', 'Î¿', 'Î´Î·', 'Î³', 'ÎµÎ¯', 'â–ÏƒÎµ', 'â–Î½Î­', 'ÎµÏ‚', 'â–ÎµÎ½', 'Î½Î¿', 'Î¹Î¿', 'Î»Î¿Î³', 'Î¹ÎºÎ­Ï‚', 'â–Î´Î¹Î±', 'Î´ÏÎ¿', 'Î¼Î­Ï‚', '.']\n",
      "\n",
      "['â–Eesti', 'â–rann', 'ikul', 'â–jal', 'ut', 'ades', 'â–vÃµib', 'â–tunnet', 'ada', 'â–mere', 'â–lÃµp', 'mat', 'ust', 'â–ja', 'â–aj', 'alo', 'ol', 'iste', 'â–jut', 'ust', 'uste', 'â–r', 'ikk', 'ust', '.']\n",
      "\n",
      "['â–Anadolu', \"'\", 'nun', 'â–mis', 'tik', 'â–atmosf', 'eri', ',', 'â–tarih', 'â–ve', 'â–kÃ¼ltÃ¼r', 'Ã¼n', 'â–har', 'man', 'land', 'Ä±ÄŸÄ±', 'â–bir', 'â–yer', 'dir', '.']\n",
      "\n",
      "['â–Cie', 'ka', 'wo', 'Å›Ä‡', 'â–i', 'â–od', 'kry', 'wanie', 'â–nowych', 'â–koncep', 'cji', 'â–stan', 'owiÄ…', 'â–fundament', 'â–naszej', 'â–lud', 'zk', 'iej', 'â–eg', 'zy', 'sten', 'cji', '.']\n",
      "\n",
      "['â–Ğ ÑƒÑ', 'ÑĞºĞ°Ñ', 'â–Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°', 'Ñ‚ÑƒÑ€Ğ°', 'â–Ğ¾Ñ‚ĞºÑ€Ñ‹', 'Ğ²Ğ°ĞµÑ‚', 'â–Ğ¿ĞµÑ€ĞµĞ´', 'â–Ğ½Ğ°Ğ¼Ğ¸', 'â–Ğ±Ğ¾Ğ³Ğ°Ñ‚', 'ÑÑ‚Ğ²Ğ¾', 'â–Ñ‡ĞµĞ»Ğ¾Ğ²Ğµ', 'Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾', 'â–Ğ¾Ğ¿Ñ‹', 'Ñ‚Ğ°', 'â–Ğ¸', 'â–Ğ¿Ğ¾', 'Ğ³Ñ€Ñƒ', 'Ğ¶Ğ°ĞµÑ‚', 'â–Ğ½Ğ°Ñ', 'â–Ğ²', 'â–Ğ³Ğ»Ñƒ', 'Ğ±Ğ¸', 'Ğ½Ñ‹', 'â–Ñ‡ĞµĞ»Ğ¾Ğ²Ğµ', 'Ñ‡ĞµÑĞºĞ¾Ğ¹', 'â–Ğ´ÑƒÑˆĞ¸', '.']\n",
      "\n",
      "['â–ÄŒeskÃ¡', 'â–kraj', 'ina', 'â–op', 'lÃ½', 'vÃ¡', 'â–mal', 'eb', 'nÃ½mi', 'â–zÃ¡', 'kout', 'Ã­', 'mi', 'â–a', 'â–histor', 'ick', 'Ã½mi', 'â–pam', 'Ã¡t', 'kami', ',', 'â–kterÃ©', 'â–vy', 'prÃ¡v', 'Ä›', 'jÃ­', 'â–pÅ™Ã­', 'bÄ›', 'hy', 'â–minul', 'osti', '.']\n",
      "\n",
      "['â–A', 'â–divers', 'idade', 'â–cultural', 'â–do', 'â–Brasil', 'â–re', 'fl', 'ete', '-', 'se', 'â–na', 'â–fus', 'Ã£o', 'â–de', 'â–influ', 'Ãªncias', 'â–ind', 'Ã­', 'gen', 'as', ',', 'â–afric', 'anas', 'â–e', 'â–europ', 'ei', 'as', ',', 'â–cri', 'ando', 'â–uma', 'â–rica', 'â–tape', 'Ã§', 'aria', 'â–de', 'â–tradi', 'Ã§Ãµes', '.']\n",
      "\n",
      "['â–De', 'â–gra', 'chten', 'â–van', 'â–Amsterdam', 'â–g', 'etu', 'igen', 'â–van', 'â–een', 'â–rij', 'ke', 'â–gesch', 'i', 'edenis', 'â–en', 'â–vor', 'men', 'â–een', 'â–intr', 'iger', 'end', 'â–net', 'werk', 'â–dat', 'â–de', 'â–stad', 'â–do', 'ork', 'ru', 'ist', '.']\n",
      "\n",
      "['â–Norges', 'â–maj', 'est', 'et', 'iske', 'â–fj', 'order', 'â–og', 'â–bort', 'g', 'jem', 'te', 'â–fj', 'ellt', 'op', 'per', 'â–lok', 'ker', 'â–event', 'yr', 'ly', 'st', 'ne', 'â–reis', 'ende', 'â–til', 'â–Ã¥', 'â–ut', 'for', 'ske', 'â–natur', 'ens', 'â–under', 'ver', 'ker', '.']\n",
      "\n",
      "['â–à´•àµ‡à´°à´³', 'à´¤àµà´¤à´¿à´¨àµà´±àµ†', 'â–à´¸àµ—', 'à´¨àµà´¦', 'à´°àµà´¯à´‚', 'â–à´ªàµà´°', 'à´•à´Ÿ', 'à´®à´¾', 'à´•àµà´•àµà´¨àµà´¨', 'â–à´…', 'à´•àµà´•à´¾', 'à´¦', 'à´®', 'à´¿à´•', 'â–à´ªà´°à´¿', 'à´¸àµà´¥', 'à´¿', 'à´¤à´¿', 'à´•àµ¾', 'â–à´¹à´¿', 'à´®à´¾', 'à´²', 'à´¯', 'à´¤àµà´¤à´¿à´¨àµà´±àµ†', 'â–à´¸à´¨àµà´¦', 'àµ¼', 'à´¶', 'à´¨', 'à´¤àµà´¤à´¿à´¨àµ', 'â–à´•àµ‡à´¨àµà´¦àµà´°', 'àµ€à´•', 'à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ', '.']\n",
      "\n",
      "['â–Sloven', 'ski', 'â–jezik', 'â–je', 'â–bogat', 'â–s', 'â–svojimi', 'â–idi', 'omat', 'skimi', 'â–iz', 'razi', ',', 'â–ki', 'â–od', 'raÅ¾', 'ajo', 'â–duhov', 'ito', 'â–nara', 'vo', 'â–in', 'â–glob', 'oko', 'â–Ä', 'ust', 'ven', 'ost', '.']\n",
      "\n",
      "['â–Del', 'ving', 'â–into', 'â–the', 'â–intr', 'ica', 'cies', 'â–of', 'â–quant', 'um', 'â–mechan', 'ics', 'â–allows', 'â–us', 'â–to', 'â–gr', 'asp', 'â–the', 'â–prof', 'o', 'und', 'â–myst', 'eries', 'â–that', 'â–govern', 'â–the', 'â–fundamental', 'â–asp', 'ects', 'â–of', 'â–the', 'â–univers', 'e', '.']\n",
      "\n",
      "['â–Den', 'â–danske', 'â–hyg', 'ge', 'â–kultur', 'â–sk', 'aber', 'â–en', 'â–atmosf', 'Ã¦re', 'â–af', 'â–varme', 'â–og', 'â–samh', 'Ã¸r', 'ighed', ',', 'â–der', 'â–om', 'f', 'av', 'ner', 'â–liv', 'ets', 'â–enk', 'le', 'â–glÃ¦', 'der', '.']\n",
      "\n",
      "['â–Suomen', 'â–lum', 'iset', 'â–mais', 'emat', 'â–tarjo', 'avat', 'â–uno', 'ht', 'um', 'att', 'oman', 'â–nÃ¤', 'k', 'ym', 'Ã¤n', 'â–poh', 'jo', 'isen', 'â–luonn', 'on', 'â–ka', 'une', 'udesta', '.']\n",
      "\n",
      "['â–Sverige', 'â–Ã¤r', 'â–kÃ¤n', 't', 'â–fÃ¶r', 'â–sin', 'â–design', 'inn', 'ov', 'ation', 'â–och', 'â–det', 'â–sÃ¤tt', 'â–pÃ¥', 'â–vilket', 'â–den', 'â–integr', 'eras', 'â–i', 'â–vard', 'agen', ',', 'â–vilket', 'â–sk', 'apar', 'â–en', 'â–harmon', 'isk', 'â–liv', 'sst', 'il', '.']\n",
      "\n",
      "['â–La', 'â–arquit', 'ectura', 'â–gÃ³', 'tica', 'â–de', 'â–la', 'â–cat', 'edral', 'â–de', 'â–Barcelona', 'â–es', 'â–un', 'â–testi', 'mon', 'io', 'â–impresion', 'ante', 'â–de', 'â–la', 'â–dest', 're', 'za', 'â–art', 'Ã­stica', 'â–y', 'â–la', 'â–devo', 'ciÃ³n', 'â–religi', 'osa', '.']\n",
      "\n",
      "['â–Die', 'â–de', 'utsche', 'â–Phil', 'os', 'ophie', 'â–hat', 'â–einen', 'â–t', 'ief', 'gre', 'if', 'enden', 'â–Ein', 'fl', 'uss', 'â–auf', 'â–das', 'â–Den', 'ken', 'â–und', 'â–die', 'â–intelle', 'ktu', 'elle', 'â–Trad', 'ition', 'â–welt', 'weit', 'â–ausge', 'Ã¼b', 't', '.']\n",
      "\n",
      "['â–L', \"'\", 'arte', 'â–cul', 'in', 'aria', 'â–italiana', 'â–Ã¨', 'â–un', \"'\", 'esperienza', 'â–sens', 'ori', 'ale', 'â–che', 'â–celebra', 'â–l', \"'\", 'amore', 'â–per', 'â–gli', 'â–ingredi', 'enti', 'â–fres', 'chi', 'â–e', 'â–la', 'â–conv', 'ivi', 'alitÃ ', '.']\n",
      "\n",
      "['â–L', \"'\", 'eff', 'erv', 'esc', 'ence', 'â–cultur', 'elle', 'â–de', 'â–Paris', ',', 'â–avec', 'â–ses', 'â–mus', 'Ã©es', ',', 'â–ses', 'â–thÃ©', 'Ã¢', 'tres', 'â–et', 'â–ses', 'â–caf', 'Ã©s', ',', 'â–fait', 'â–de', 'â–la', 'â–ville', 'â–une', 'â–destination', 'â–artisti', 'que', 'â–incon', 'to', 'urn', 'able', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = mt_model.translator.tokenizer\n",
    "\n",
    "sents = [\n",
    "    'Î— ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Ï„Î·Ï‚ Î±Î½Î¸ÏÏÏ€Î¹Î½Î·Ï‚ Ï†ÏÏƒÎ·Ï‚ ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î±Ï„Î­Î»ÎµÎ¹Ï‰Ï„Î· Ï€ÎµÏÎ¹Ï€Î­Ï„ÎµÎ¹Î± Ï€Î¿Ï… Î¼Î±Ï‚ ÎºÎ±Î¸Î¿Î´Î·Î³ÎµÎ¯ ÏƒÎµ Î½Î­ÎµÏ‚ ÎµÎ½Î½Î¿Î¹Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î­Ï‚.',\n",
    "    'Eesti rannikul jalutades vÃµib tunnetada mere lÃµpmatust ja ajalooliste jutustuste rikkust.',\n",
    "    \"Anadolu'nun mistik atmosferi, tarih ve kÃ¼ltÃ¼rÃ¼n harmanlandÄ±ÄŸÄ± bir yerdir.\",\n",
    "    'CiekawoÅ›Ä‡ i odkrywanie nowych koncepcji stanowiÄ… fundament naszej ludzkiej egzystencji.',\n",
    "    'Ğ ÑƒÑÑĞºĞ°Ñ Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ´ Ğ½Ğ°Ğ¼Ğ¸ Ğ±Ğ¾Ğ³Ğ°Ñ‚ÑÑ‚Ğ²Ğ¾ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ° Ğ¸ Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ½Ğ°Ñ Ğ² Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ Ğ´ÑƒÑˆĞ¸.',\n",
    "    'ÄŒeskÃ¡ krajina oplÃ½vÃ¡ malebnÃ½mi zÃ¡koutÃ­mi a historickÃ½mi pamÃ¡tkami, kterÃ© vyprÃ¡vÄ›jÃ­ pÅ™Ã­bÄ›hy minulosti.',\n",
    "    'A diversidade cultural do Brasil reflete-se na fusÃ£o de influÃªncias indÃ­genas, africanas e europeias, criando uma rica tapeÃ§aria de tradiÃ§Ãµes.',\n",
    "    'De grachten van Amsterdam getuigen van een rijke geschiedenis en vormen een intrigerend netwerk dat de stad doorkruist.',\n",
    "    'Norges majestetiske fjorder og bortgjemte fjelltopper lokker eventyrlystne reisende til Ã¥ utforske naturens underverker.',\n",
    "    'à´•àµ‡à´°à´³à´¤àµà´¤à´¿à´¨àµà´±àµ† à´¸àµ—à´¨àµà´¦à´°àµà´¯à´‚ à´ªàµà´°à´•à´Ÿà´®à´¾à´•àµà´•àµà´¨àµà´¨ à´…à´•àµà´•à´¾à´¦à´®à´¿à´• à´ªà´°à´¿à´¸àµà´¥à´¿à´¤à´¿à´•àµ¾ à´¹à´¿à´®à´¾à´²à´¯à´¤àµà´¤à´¿à´¨àµà´±àµ† à´¸à´¨àµà´¦àµ¼à´¶à´¨à´¤àµà´¤à´¿à´¨àµ à´•àµ‡à´¨àµà´¦àµà´°àµ€à´•à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ.',\n",
    "    'Slovenski jezik je bogat s svojimi idiomatskimi izrazi, ki odraÅ¾ajo duhovito naravo in globoko Äustvenost.',\n",
    "    'Delving into the intricacies of quantum mechanics allows us to grasp the profound mysteries that govern the fundamental aspects of the universe.',\n",
    "    'Den danske hygge kultur skaber en atmosfÃ¦re af varme og samhÃ¸righed, der omfavner livets enkle glÃ¦der.',\n",
    "    'Suomen lumiset maisemat tarjoavat unohtumattoman nÃ¤kymÃ¤n pohjoisen luonnon kauneudesta.',\n",
    "    'Sverige Ã¤r kÃ¤nt fÃ¶r sin designinnovation och det sÃ¤tt pÃ¥ vilket den integreras i vardagen, vilket skapar en harmonisk livsstil.',\n",
    "    'La arquitectura gÃ³tica de la catedral de Barcelona es un testimonio impresionante de la destreza artÃ­stica y la devociÃ³n religiosa.',\n",
    "    'Die deutsche Philosophie hat einen tiefgreifenden Einfluss auf das Denken und die intellektuelle Tradition weltweit ausgeÃ¼bt.',\n",
    "    \"L'arte culinaria italiana Ã¨ un'esperienza sensoriale che celebra l'amore per gli ingredienti freschi e la convivialitÃ .\",\n",
    "    \"L'effervescence culturelle de Paris, avec ses musÃ©es, ses thÃ©Ã¢tres et ses cafÃ©s, fait de la ville une destination artistique incontournable.\",\n",
    "]\n",
    "encodings = tokenizer(sents, truncation=False, padding=False, return_attention_mask=False, add_special_tokens=False)\n",
    "\n",
    "for tok_ids in encodings['input_ids']:\n",
    "    print([tokenizer.convert_ids_to_tokens(tok_id) for tok_id in tok_ids])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPUS-MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_model = EasyNMT('opus-mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = mt_model.translator.models['Helsinki-NLP/opus-mt-en-de']['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [16816, 2, 360, 68]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, world!'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer('Hello, world!', return_attention_mask=False, add_special_tokens=False)\n",
    "print(encoding)\n",
    "tokenizer.decode(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['â–Hello', ',', 'â–world', '!']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Hello, world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b61304ba204149b33c07aa06f301de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e8fc5a41bb46b981c6f1e4742ec340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143cf6534d134053968fe18550f590ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e982a6b9164eada7323cb3edad6afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c7aec399e4feb95b7a3dc4b3ad38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60d458b060645b28d24bc1a741a443d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b34c7c85f44bc6ba7580824cf315c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hallo Welt!'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_model.translate('Hello world!', source_lang='en', target_lang='de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = \"\"\"\n",
    "English\ten\tThe suspense was unbearable â€¦ the door creaked open.\n",
    "English\ten\tâ” remove all the stress from your life\n",
    "French\tfr\tIl a Ã©crit un roman Â«Le MystÃ¨reÂ» qui est devenu un best-seller.\n",
    "German\tde\tDie Spannung war unertrÃ¤glichâ€¦ die TÃ¼r quietschte.\n",
    "German\tde\tEr schrieb einen Roman â€Das Geheimnisâ€, der ein Bestseller wurde.\n",
    "\"\"\"\n",
    "sents = [row.split('\\t') for row in  sents.split('\\n') if row != '']\n",
    "sents_df = pd.DataFrame(sents, columns=['language', 'code', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "--------------------\n",
      "Die Spannung war unertrÃ¤glichâ€¦ die TÃ¼r quietschte.\n",
      "Die Spannung war unertrÃ¤glich... die TÃ¼r quietschte.\n",
      "\n",
      "Er schrieb einen Roman â€Das Geheimnisâ€, der ein Bestseller wurde.\n",
      "Er schrieb einen Roman \"Das Geheimnis\", der ein Bestseller wurde.\n",
      "\n",
      "en\n",
      "--------------------\n",
      "The suspense was unbearable â€¦ the door creaked open.\n",
      "The suspense was unbearable ... the door creaked open.\n",
      "\n",
      "â” remove all the stress from your life\n",
      "- remove all the stress from your life\n",
      "\n",
      "fr\n",
      "--------------------\n",
      "Il a Ã©crit un roman Â«Le MystÃ¨reÂ» qui est devenu un best-seller.\n",
      "Il a Ã©crit un roman \"Le MystÃ¨re\" qui est devenu un best-seller.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sacremoses import MosesPunctNormalizer # see https://github.com/hplt-project/sacremoses/blob/master/sacremoses/normalize.py\n",
    "for lang, d in sents_df.groupby('code'):\n",
    "    print(lang, '-'*20, sep='\\n')\n",
    "    punct_normalizer = MosesPunctNormalizer(lang=lang, pre_replace_unicode_punct=True, post_remove_control_chars=True)\n",
    "    for text in d.text:\n",
    "        print(text, punct_normalizer.normalize(text), '', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages with non-Latin scripts\n",
    "\n",
    "When we work with texts written in Spanish, English, German, French, and so on, we work with Romanic languages that use the Roman script and the Latin alphabet.\n",
    "However, there are many languages that use other scripts:\n",
    "\n",
    "- *Cyrillic script*: Used for Russian, Bulgarian, Serbian, and many other Slavic languages.\n",
    "- *Arabic script*: Used for Arabic, Persian, Urdu, and several other languages in the Middle East and North Africa.\n",
    "- *Devanagari script*: Used for Hindi, Sanskrit, Marathi, and other Indian languages.\n",
    "- *Hanzi*: Used for Mandarin, Cantonese, and other Chinese languages.\n",
    "- *Hangul script*: Used for Korean.\n",
    "- *Hebrew script*: Used for Hebrew.\n",
    "- *Greek script*: Used for Greek.\n",
    "- *Georgian script*: Used for Georgian.\n",
    "- *Katakana and Hiragana scripts*: Used for Japanese.\n",
    "- *Tamil script*: Used for Tamil.\n",
    "- *Thai script*: Used for Thai.\n",
    "- *Coptic script*: Used for the Coptic language.\n",
    "- *Armenian script*: Used for Armenian.\n",
    "- *Bengali script*: Used for Bengali and Assamese.\n",
    "- *Gurmukhi script*: Used for Punjabi.\n",
    "- *Khmer script*: Used for Khmer (Cambodian).\n",
    "- *Lao script*: Used for Lao.\n",
    "- *Mongolian script*: Used for Mongolian.\n",
    "- *Tibetan script*: Used for Tibetan.\n",
    "- *Syriac script*: Used for various languages in the Syriac community.\n",
    "\n",
    "Because of the historical developemnet of the field of computational linguistics, \n",
    "we have a wide range of tools and resources available pre-processing and tokenizing English texts and texts written in other Romanic languages, but fev tools and resources for other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translitaration\n",
    "\n",
    "Transliteration is the process of converting text or words from one script into another script.\n",
    "It means to represent the characters of one writing system with equivalent characters of another system.\n",
    "In linguistics, the purpose of transliteration is to facilitate the pronunciation or understanding of words written in a script that may be unfamiliar to the reader.\n",
    "But in machine translation and multilingual NLP, transliteration is also used as a common pre-processing step applied to non-Latin languages (e.g., [here](https://github.com/yannvgn/laserembeddings/blob/master/laserembeddings/preprocessing.py#L108))\n",
    "\n",
    "For example, when transliterating from the Cyrillic script to the Latin script, as in the case of Russian, the Cyrillic characters are replaced with their Latin counterparts while attempting to preserve the original pronunciation.\n",
    "Importantly, transliteration does *not* involve translation of the meaning of words; it is solely concerned with representing the characters of one script in another!\n",
    "\n",
    "### Transliteration systems\n",
    "\n",
    "To map characters from one script to another, we need a transliteration system that defines the rules for this process.\n",
    "There are different standards for transliterating between specific pairs of scripts.\n",
    "Common transliteration systems include the *International Alphabet of Sanskrit Transliteration* ([IAST](https://en.wikipedia.org/wiki/International_Alphabet_of_Sanskrit_Transliteration)) for Sanskrit and other Indic languages, and the [BGN/PCGN](https://en.wikipedia.org/wiki/BGN/PCGN_romanization) system for Romanization of Cyrillic scripts, among others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translitarating Cyrilic to Latin (\"Romanize\")\n",
    "\n",
    "There is a nice package for transliterating Cyrillic to Latin script in Python: [transliterate](https://github.com/barseghyanartur/transliterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transliterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = \"\"\"\n",
    "Armenian\thy\tÔ²Õ¡Ö€Õ¥Ö‚ Õ¡Õ·Õ­Õ¡Ö€Õ°!\tBarev ashkharh!\tHello, world!\n",
    "Bulgarian\tbg\tĞ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹, ÑĞ²ÑÑ‚!\tZdravey, svyat!\tHello, world!\n",
    "Georgian\tka\táƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ, áƒ›áƒ¡áƒáƒ¤áƒšáƒ˜áƒ!\tGamajoba, msoplio!\tHello, world!\n",
    "Greek\tel\tÎ“ÎµÎ¹Î± ÏƒÎ¿Ï…, ÎºÏŒÏƒÎ¼Îµ!\tYia sou, kosme!\tHello, world!\n",
    "Macedonian\tmk\tĞ—Ğ´Ñ€Ğ°Ğ²Ğ¾, ÑĞ²ĞµÑ‚Ñƒ!\tZdravo, svetu!\tHello, world!\n",
    "Mongolian\tmn\tĞ¡Ğ°Ğ¹Ğ½ Ğ±Ğ°Ğ¹Ğ½Ğ° ÑƒÑƒ, Ğ´ÑĞ»Ñ…Ğ¸Ğ¹!\tSain baina uu, delkhi!\tHello, world!\n",
    "Russian\tru\tĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ğ¼Ğ¸Ñ€!\tPrivet, mir!\tHello, world!\n",
    "Serbian\tsr\tĞ—Ğ´Ñ€Ğ°Ğ²Ğ¾, ÑĞ²ĞµÑ‚Ğµ!\tZdravo, svete!\tHello, world!\n",
    "Ukrainian\tuk\tĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚, ÑĞ²Ñ–Ñ‚!\tPrivit, svit!\tHello, world!\n",
    "\"\"\"\n",
    "sents = [row.split('\\t') for row in  sents.split('\\n') if row != '']\n",
    "sents_df = pd.DataFrame(sents, columns=['language', 'code', 'text', 'transliteration', 'translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transliterate import translit, get_available_language_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(sents_df.code.isin(get_available_language_codes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hy\tÔ²Õ¡Ö€Õ¥Ö‚ Õ¡Õ·Õ­Õ¡Ö€Õ°!\tBareÖ‚ ashxarh!\n",
      "bg\tĞ—Ğ´Ñ€Ğ°Ğ²ĞµĞ¹, ÑĞ²ÑÑ‚!\tZdravey, svyat!\n",
      "ka\táƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ, áƒ›áƒ¡áƒáƒ¤áƒšáƒ˜áƒ!\tgamarjoba, msoflio!\n",
      "el\tÎ“ÎµÎ¹Î± ÏƒÎ¿Ï…, ÎºÏŒÏƒÎ¼Îµ!\tGeia soy, kosme!\n",
      "mk\tĞ—Ğ´Ñ€Ğ°Ğ²Ğ¾, ÑĞ²ĞµÑ‚Ñƒ!\tZdravo, svetu!\n",
      "mn\tĞ¡Ğ°Ğ¹Ğ½ Ğ±Ğ°Ğ¹Ğ½Ğ° ÑƒÑƒ, Ğ´ÑĞ»Ñ…Ğ¸Ğ¹!\tSain baina uu, delkhii!\n",
      "ru\tĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ğ¼Ğ¸Ñ€!\tPrivet, mir!\n",
      "sr\tĞ—Ğ´Ñ€Ğ°Ğ²Ğ¾, ÑĞ²ĞµÑ‚Ğµ!\tZdravo, svete!\n",
      "uk\tĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚, ÑĞ²Ñ–Ñ‚!\tPryvit, svit!\n"
     ]
    }
   ],
   "source": [
    "for i, d in sents_df.iterrows():\n",
    "    print(d.code, d.text, translit(d.text, d.code, reversed=True), sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilingual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
